{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUfByvSjNw/uhbdncdYUPX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/COLMEX-ML/blob/main/Semana_10_CENSO_DENUE_COLMEX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pto540nBZ41x"
      },
      "outputs": [],
      "source": [
        "#https://drive.google.com/file/d/1WcTuLEkICVg2A9j98EZWuSgjUhO8AIRI/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1gYWtwKDpJK0_uBOJvvwkXK8Hy8w8mL0p/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1LVPNaUxto31HE-UQIO1-4l6XPER9Ry5l/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1WcTuLEkICVg2A9j98EZWuSgjUhO8AIRI"
      ],
      "metadata": {
        "id": "aU-jBjAFaFUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1gYWtwKDpJK0_uBOJvvwkXK8Hy8w8mL0p"
      ],
      "metadata": {
        "id": "SWNpnkAJc0PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1LVPNaUxto31HE-UQIO1-4l6XPER9Ry5l"
      ],
      "metadata": {
        "id": "ywKYrzZ2c0Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely import wkb\n",
        "import joblib\n",
        "from typing import Dict\n"
      ],
      "metadata": {
        "id": "Y30Vmix3Z7qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_modelo(ruta_modelo: str):\n",
        "    \"\"\"Carga el modelo entrenado desde un archivo.\"\"\"\n",
        "    return joblib.load(ruta_modelo)\n",
        "\n",
        "def extraer_caracteristicas(lat: float, lon: float, denue_db_path: str, censo_db_path: str) -> pd.DataFrame:\n",
        "    conn = duckdb.connect(':memory:')\n",
        "    conn.execute(\"INSTALL spatial; LOAD spatial;\")\n",
        "\n",
        "    # Crear geometría del punto y buffers\n",
        "    conn.execute(f\"\"\"\n",
        "        CREATE TEMP TABLE nuevo_punto AS\n",
        "        SELECT\n",
        "            ST_GeomFromText('POINT({lon} {lat})') AS geometry,\n",
        "            ST_Buffer(ST_GeomFromText('POINT({lon} {lat})'), 0.000898) AS buffer_100,\n",
        "            ST_Buffer(ST_GeomFromText('POINT({lon} {lat})'), 0.00449) AS buffer_500\n",
        "    \"\"\")\n",
        "\n",
        "    # Conectar a bases de datos\n",
        "    conn.execute(f\"ATTACH '{denue_db_path}' AS denue_db\")\n",
        "    conn.execute(f\"ATTACH '{censo_db_path}' AS censo_db\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # 1. Características de DENUE (actividades y personal)\n",
        "    # =========================================================================\n",
        "    act_codes = ['46', '51', '54', '11', '22', '52', '71', '43', '31', '61',\n",
        "                 '23', '55', '93', '53', '81', '33', '48', '32', '56', '49',\n",
        "                 '62', '21', '72']\n",
        "\n",
        "    features = {\n",
        "        'epo_100': 0,\n",
        "        'epo_500': 0,\n",
        "        **{f'act_{code}_100': 0 for code in act_codes},\n",
        "        **{f'act_{code}_500': 0 for code in act_codes},\n",
        "    }\n",
        "\n",
        "    # DENUE - Actividades en buffer 100m\n",
        "    denue_100 = conn.execute(\"\"\"\n",
        "        SELECT d.codigo_act_2c, SUM(d.est_per_ocu) AS total\n",
        "        FROM denue_db.denue_est_per_ocu d\n",
        "        JOIN nuevo_punto n ON ST_Intersects(d.geometry, n.buffer_100)\n",
        "        GROUP BY d.codigo_act_2c\n",
        "    \"\"\").fetchdf()\n",
        "    for _, row in denue_100.iterrows():\n",
        "        code = row['codigo_act_2c']\n",
        "        if code in act_codes:\n",
        "            features[f'act_{code}_100'] = row['total']\n",
        "\n",
        "    # DENUE - Actividades en buffer 500m\n",
        "    denue_500 = conn.execute(\"\"\"\n",
        "        SELECT d.codigo_act_2c, SUM(d.est_per_ocu) AS total\n",
        "        FROM denue_db.denue_est_per_ocu d\n",
        "        JOIN nuevo_punto n ON ST_Intersects(d.geometry, n.buffer_500)\n",
        "        GROUP BY d.codigo_act_2c\n",
        "    \"\"\").fetchdf()\n",
        "    for _, row in denue_500.iterrows():\n",
        "        code = row['codigo_act_2c']\n",
        "        if code in act_codes:\n",
        "            features[f'act_{code}_500'] = row['total']\n",
        "\n",
        "    # DENUE - Personal ocupado total\n",
        "    features['epo_100'] = conn.execute(\"\"\"\n",
        "        SELECT COALESCE(SUM(d.est_per_ocu), 0)\n",
        "        FROM denue_db.denue_est_per_ocu d\n",
        "        JOIN nuevo_punto n ON ST_Intersects(d.geometry, n.buffer_100)\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    features['epo_500'] = conn.execute(\"\"\"\n",
        "        SELECT COALESCE(SUM(d.est_per_ocu), 0)\n",
        "        FROM denue_db.denue_est_per_ocu d\n",
        "        JOIN nuevo_punto n ON ST_Intersects(d.geometry, n.buffer_500)\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    # =========================================================================\n",
        "    # 2. Características del Censo\n",
        "    # =========================================================================\n",
        "    # Obtener todas las variables del censo usadas en el entrenamiento\n",
        "    variables_censo = [\n",
        "        'POBTOT', 'POBFEM', 'POBMAS', 'P_0A2', 'P_0A2_F', 'P_0A2_M',\n",
        "        'P_3YMAS', 'P_3YMAS_F', 'P_3YMAS_M', 'P_5YMAS', 'P_5YMAS_F',\n",
        "        'P_5YMAS_M', 'P_12YMAS', 'P_12YMAS_F', 'P_12YMAS_M', 'P_15YMAS',\n",
        "        'P_15YMAS_F', 'P_15YMAS_M', 'P_18YMAS', 'P_18YMAS_F', 'P_18YMAS_M',\n",
        "        'P_3A5', 'P_3A5_F', 'P_3A5_M', 'P_6A11', 'P_6A11_F', 'P_6A11_M',\n",
        "        'P_8A14', 'P_8A14_F', 'P_8A14_M', 'P_12A14', 'P_12A14_F',\n",
        "        'P_12A14_M', 'P_15A17', 'P_15A17_F', 'P_15A17_M', 'P_18A24',\n",
        "        'P_18A24_F', 'P_18A24_M', 'P_15A49_F', 'P_60YMAS', 'P_60YMAS_F',\n",
        "        'P_60YMAS_M', 'REL_H_M', 'POB0_14', 'POB15_64', 'POB65_MAS',\n",
        "        'PROM_HNV', 'PNACENT', 'PNACENT_F', 'PNACENT_M', 'PNACOE', 'PNACOE_F',\n",
        "        'PNACOE_M', 'PRES2015', 'PRES2015_F', 'PRES2015_M', 'PRESOE15',\n",
        "        'PRESOE15_F', 'PRESOE15_M', 'P3YM_HLI', 'P3YM_HLI_F', 'P3YM_HLI_M',\n",
        "        'P3HLINHE', 'P3HLINHE_F', 'P3HLINHE_M', 'P3HLI_HE', 'P3HLI_HE_F',\n",
        "        'P3HLI_HE_M', 'P5_HLI', 'P5_HLI_NHE', 'P5_HLI_HE', 'PHOG_IND',\n",
        "        'POB_AFRO', 'POB_AFRO_F', 'POB_AFRO_M', 'PCON_DISC', 'PCDISC_MOT',\n",
        "        'PCDISC_VIS', 'PCDISC_LENG', 'PCDISC_AUD', 'PCDISC_MOT2', 'PCDISC_MEN',\n",
        "        'PCON_LIMI', 'PCLIM_CSB', 'PCLIM_VIS', 'PCLIM_HACO', 'PCLIM_OAUD',\n",
        "        'PCLIM_MOT2', 'PCLIM_RE_CO', 'PCLIM_PMEN', 'PSIND_LIM', 'P3A5_NOA',\n",
        "        'P3A5_NOA_F', 'P3A5_NOA_M', 'P6A11_NOA', 'P6A11_NOAF', 'P6A11_NOAM',\n",
        "        'P12A14NOA', 'P12A14NOAF', 'P12A14NOAM', 'P15A17A', 'P15A17A_F',\n",
        "        'P15A17A_M', 'P18A24A', 'P18A24A_F', 'P18A24A_M', 'P8A14AN',\n",
        "        'P8A14AN_F', 'P8A14AN_M', 'P15YM_AN', 'P15YM_AN_F', 'P15YM_AN_M',\n",
        "        'P15YM_SE', 'P15YM_SE_F', 'P15YM_SE_M', 'P15PRI_IN', 'P15PRI_INF',\n",
        "        'P15PRI_INM', 'P15PRI_CO', 'P15PRI_COF', 'P15PRI_COM', 'P15SEC_IN',\n",
        "        'P15SEC_INF', 'P15SEC_INM', 'P15SEC_CO', 'P15SEC_COF', 'P15SEC_COM',\n",
        "        'P18YM_PB', 'P18YM_PB_F', 'P18YM_PB_M', 'GRAPROES', 'GRAPROES_F',\n",
        "        'GRAPROES_M', 'PEA', 'PEA_F', 'PEA_M', 'PE_INAC', 'PE_INAC_F',\n",
        "        'PE_INAC_M', 'POCUPADA', 'POCUPADA_F', 'POCUPADA_M', 'PDESOCUP',\n",
        "        'PDESOCUP_F', 'PDESOCUP_M', 'PSINDER', 'PDER_SS', 'PDER_IMSS',\n",
        "        'PDER_ISTE', 'PDER_ISTEE', 'PAFIL_PDOM', 'PDER_SEGP', 'PDER_IMSSB',\n",
        "        'PAFIL_IPRIV', 'PAFIL_OTRAI', 'P12YM_SOLT', 'P12YM_CASA', 'P12YM_SEPA',\n",
        "        'PCATOLICA', 'PRO_CRIEVA', 'POTRAS_REL', 'PSIN_RELIG', 'TOTHOG',\n",
        "        'HOGJEF_F', 'HOGJEF_M', 'POBHOG', 'PHOGJEF_F', 'PHOGJEF_M', 'VIVTOT',\n",
        "        'TVIVHAB', 'TVIVPAR', 'VIVPAR_HAB', 'VIVPARH_CV', 'TVIVPARHAB',\n",
        "        'VIVPAR_DES', 'VIVPAR_UT', 'OCUPVIVPAR', 'PROM_OCUP', 'PRO_OCUP_C',\n",
        "        'VPH_PISODT', 'VPH_PISOTI', 'VPH_1DOR', 'VPH_2YMASD', 'VPH_1CUART',\n",
        "        'VPH_2CUART', 'VPH_3YMASC', 'VPH_C_ELEC', 'VPH_S_ELEC', 'VPH_AGUADV',\n",
        "        'VPH_AEASP', 'VPH_AGUAFV', 'VPH_TINACO', 'VPH_CISTER', 'VPH_EXCSA',\n",
        "        'VPH_LETR', 'VPH_DRENAJ', 'VPH_NODREN', 'VPH_C_SERV', 'VPH_NDEAED',\n",
        "        'VPH_DSADMA', 'VPH_NDACMM', 'VPH_SNBIEN', 'VPH_REFRI', 'VPH_LAVAD',\n",
        "        'VPH_HMICRO', 'VPH_AUTOM', 'VPH_MOTO', 'VPH_BICI', 'VPH_RADIO', 'VPH_TV',\n",
        "        'VPH_PC', 'VPH_TELEF', 'VPH_CEL', 'VPH_INTER', 'VPH_STVP', 'VPH_SPMVPI',\n",
        "        'VPH_CVJ', 'VPH_SINRTV', 'VPH_SINLTC', 'VPH_SINCINT', 'VPH_SINTIC'\n",
        "    ]\n",
        "\n",
        "    # Agregar variables del censo para buffer 100m\n",
        "    censo_100 = conn.execute(f\"\"\"\n",
        "        SELECT {', '.join([f'COALESCE(SUM({var}), 0) AS {var}_100' for var in variables_censo])}\n",
        "        FROM denue_db.censo_geo_int_centroid c\n",
        "        JOIN nuevo_punto n ON ST_Intersects(c.geometry, n.buffer_100)\n",
        "    \"\"\").fetchone()\n",
        "\n",
        "    # Agregar variables del censo para buffer 500m\n",
        "    censo_500 = conn.execute(f\"\"\"\n",
        "        SELECT {', '.join([f'COALESCE(SUM({var}), 0) AS {var}_500' for var in variables_censo])}\n",
        "        FROM denue_db.censo_geo_int_centroid c\n",
        "        JOIN nuevo_punto n ON ST_Intersects(c.geometry, n.buffer_500)\n",
        "    \"\"\").fetchone()\n",
        "\n",
        "    # Combinar todas las features\n",
        "    features.update({\n",
        "        f'censo_{var}_100': censo_100[i] for i, var in enumerate(variables_censo)\n",
        "    })\n",
        "    features.update({\n",
        "        f'censo_{var}_500': censo_500[i] for i, var in enumerate(variables_censo)\n",
        "    })\n",
        "\n",
        "    # =========================================================================\n",
        "    # 3. Asegurar el orden correcto de las columnas\n",
        "    # =========================================================================\n",
        "    # Obtener nombres de features del modelo entrenado\n",
        "    modelo = joblib.load('trained_model.joblib')\n",
        "    expected_features = modelo.feature_names_in_\n",
        "\n",
        "    # Crear DataFrame con todas las columnas esperadas\n",
        "    df = pd.DataFrame([features])\n",
        "\n",
        "    # Añadir columnas faltantes con 0\n",
        "    for col in expected_features:\n",
        "        if col not in df.columns:\n",
        "            df[col] = 0\n",
        "\n",
        "    # Reordenar columnas como el modelo espera\n",
        "    df = df[expected_features]\n",
        "\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "def predecir_probabilidad(lat: float, lon: float, ruta_modelo: str,\n",
        "                          denue_db_path: str, censo_db_path: str) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Predice la probabilidad de que el punto sea OXXO (1) o Tienda de Abarrotes (0).\n",
        "    \"\"\"\n",
        "    modelo = cargar_modelo(ruta_modelo)\n",
        "    features = extraer_caracteristicas(lat, lon, denue_db_path, censo_db_path)\n",
        "    proba = modelo.predict_proba(features)[0]\n",
        "    return {1: proba[1], 0: proba[0]}"
      ],
      "metadata": {
        "id": "Fy0KPXDUaXyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lat=19.4326\n",
        "lon=-99.1332\n",
        "denue_db_path='/content/denue_total_est_per_ocu_final_5.duckdb'\n",
        "censo_db_path='/content/datos_censo_nacional_s9.duckdb'"
      ],
      "metadata": {
        "id": "KMl6osUfhPnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "probabilidades = predecir_probabilidad(\n",
        "    lat=lat,\n",
        "    lon=lon,\n",
        "    ruta_modelo='trained_model.joblib',\n",
        "    denue_db_path=denue_db_path,\n",
        "    censo_db_path=censo_db_path\n",
        ")\n",
        "print(f\"Probabilidad OXXO (1): {probabilidades[1]:.2f}\")\n",
        "print(f\"Probabilidad Tienda (0): {probabilidades[0]:.2f}\")"
      ],
      "metadata": {
        "id": "fw_0y_1TdY_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dfWgvb4Agjqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caracteristicas = extraer_caracteristicas(lat, lon, denue_db_path, censo_db_path)"
      ],
      "metadata": {
        "id": "8C4VxwSkdh2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caracteristicas"
      ],
      "metadata": {
        "id": "e5QiGIG5f7X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lat=21.861708391534815\n",
        "lon=-102.29364061708422\n",
        "#,"
      ],
      "metadata": {
        "id": "3o2MkmyvhZU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilidades = predecir_probabilidad(\n",
        "    lat=lat,\n",
        "    lon=lon,\n",
        "    ruta_modelo='trained_model.joblib',\n",
        "    denue_db_path=denue_db_path,\n",
        "    censo_db_path=censo_db_path\n",
        ")\n",
        "print(f\"Probabilidad OXXO (1): {probabilidades[1]:.2f}\")\n",
        "print(f\"Probabilidad Tienda (0): {probabilidades[0]:.2f}\")"
      ],
      "metadata": {
        "id": "SCrMkdzgjSK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "khrw-kBxjUW2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}