{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM8L9djhSZmGRsc5sab2T9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/COLMEX-ML/blob/main/Semana_05_00_COLMEX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö Tutorial Interactivo de K-means: Entiende y Visualiza el Algoritmo\n",
        "\n",
        "En este tutorial aprender√°s de forma interactiva c√≥mo K-means agrupa datos y encuentra centroides utilizando Python en Google Colab.\n",
        "\n",
        "**Objetivos:**\n",
        "- Comprender el proceso iterativo de asignaci√≥n y actualizaci√≥n de centroides.\n",
        "- Visualizar la formaci√≥n de clusters en datos sint√©ticos y reales.\n",
        "- Explorar el \"M√©todo del Codo\" para elegir el n√∫mero √≥ptimo de clusters."
      ],
      "metadata": {
        "id": "Lr77QVVNtEWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî∞ Paso 1: Configurar el Entorno\n",
        "Importamos las librer√≠as esenciales para el an√°lisis num√©rico y la visualizaci√≥n."
      ],
      "metadata": {
        "id": "OfV7-37gtKAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn --quiet\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs, load_iris\n",
        "plt.style.use('ggplot')"
      ],
      "metadata": {
        "id": "ETf-LWPLs4Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üé® Paso 2: Crear Datos de Prueba\n",
        "Generamos datos sint√©ticos con 300 puntos distribuidos en 3 grupos (clusters).\n",
        "Ajusta `cluster_std` para modificar la dispersi√≥n de los puntos.\n"
      ],
      "metadata": {
        "id": "1WCJIhNDtnGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, _ = make_blobs(\n",
        "    n_samples=300,      # 300 puntos\n",
        "    centers=3,          # 3 clusters\n",
        "    cluster_std=0.8,    # Desviaci√≥n est√°ndar de cada cluster\n",
        "    random_state=10     # Semilla para reproducibilidad\n",
        ")"
      ],
      "metadata": {
        "id": "_9_fQW1HtOa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos los datos originales:\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(X[:, 0], X[:, 1], s=50, color='skyblue')\n",
        "plt.title(\"Datos Originales\")\n",
        "plt.xlabel(\"Caracter√≠stica 1\")\n",
        "plt.ylabel(\"Caracter√≠stica 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TzoygzakttRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü§ñ Paso 3: Aplicar K-means\n",
        "Configuramos y entrenamos el modelo K-means con 3 clusters.\n",
        "Par√°metros clave:\n",
        "- **init='random'**: Inicializaci√≥n aleatoria de los centroides.\n",
        "- **n_init=10**: Se realizan 10 ejecuciones para elegir la mejor soluci√≥n.\n",
        "- **max_iter=300**: M√°ximo n√∫mero de iteraciones por ejecuci√≥n.\n"
      ],
      "metadata": {
        "id": "ujGEdg5kuBK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(\n",
        "    n_clusters=3,\n",
        "    init='random',\n",
        "    n_init=10,\n",
        "    max_iter=300,\n",
        "    random_state=42\n",
        ")\n",
        "kmeans.fit(X)"
      ],
      "metadata": {
        "id": "gonrZLMHt8Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Paso 4: Visualizar los Resultados\n",
        "Mostramos c√≥mo K-means ha agrupado los datos y la ubicaci√≥n final de los centroides.\n"
      ],
      "metadata": {
        "id": "P9YTxWJMuLyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "# Definimos colores para distinguir los clusters:\n",
        "colores = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "etiquetas = kmeans.labels_\n",
        "\n",
        "# Graficamos cada cluster:\n",
        "for i in range(3):\n",
        "    plt.scatter(\n",
        "        X[etiquetas == i, 0],\n",
        "        X[etiquetas == i, 1],\n",
        "        s=50,\n",
        "        color=colores[i],\n",
        "        label=f'Cluster {i+1}'\n",
        "    )\n",
        "\n",
        "# Graficamos los centroides con una estrella dorada:\n",
        "plt.scatter(\n",
        "    kmeans.cluster_centers_[:, 0],\n",
        "    kmeans.cluster_centers_[:, 1],\n",
        "    s=200,\n",
        "    marker='*',\n",
        "    color='gold',\n",
        "    edgecolor='black',\n",
        "    linewidth=1,\n",
        "    label='Centroides'\n",
        ")\n",
        "\n",
        "plt.title(\"üîç Resultado del Clustering\")\n",
        "plt.xlabel(\"Caracter√≠stica 1\")\n",
        "plt.ylabel(\"Caracter√≠stica 2\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gb_hmvliuIJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÑ Paso 5: Evoluci√≥n de los Centroides\n",
        "Visualizamos c√≥mo se mueven los centroides a lo largo de las iteraciones.\n",
        "Esta funci√≥n muestra el estado del clustering tras 1, 2 y 3 iteraciones.\n",
        "\n",
        "A grandes rasgos, el algoritmo K-means sigue este flujo:\n",
        "\n",
        "1. **Inicializaci√≥n Aleatoria de Centroides**  \n",
        "   - Se eligen aleatoriamente $k$ posiciones en el espacio de los datos para ubicar los centroides iniciales.  \n",
        "   - Estos centroides representan el ‚Äúcentro‚Äù temporal de cada uno de los $k$ grupos (clusters) que queremos encontrar.\n",
        "\n",
        "2. **Asignaci√≥n de Puntos**  \n",
        "   - En cada iteraci√≥n, cada dato se asigna al grupo cuyo centroide est√© m√°s cerca.  \n",
        "   - En la pr√°ctica, esto se hace calculando la distancia (generalmente Euclidiana) entre el punto y cada centroide, y luego seleccionando el m√≠nimo.\n",
        "\n",
        "3. **Actualizaci√≥n de Centroides**  \n",
        "   - Para cada grupo, se recalcula la posici√≥n del centroide como el promedio (media) de todos los puntos que han sido asignados a ese grupo.  \n",
        "\n",
        "4. **Iteraci√≥n y Convergencia**  \n",
        "   - Con las nuevas posiciones de los centroides, se repite el proceso de asignaci√≥n y actualizaci√≥n.  \n",
        "   - A medida que avanzan las iteraciones, los centroides ‚Äúmigran‚Äù hacia la regi√≥n donde se concentra la mayor parte de los puntos de cada grupo.  \n",
        "   - Este movimiento se va haciendo m√°s peque√±o hasta que los centroides se estabilizan (o se llega al n√∫mero m√°ximo de iteraciones), indicando que los clusters est√°n bien definidos.\n",
        "\n",
        "---\n",
        "\n",
        "### ¬øPor qu√© converge tan r√°pido en la pr√°ctica?\n",
        "\n",
        "- **Implementaciones Eficientes:**  \n",
        "  Bibliotecas como *scikit-learn* utilizan versiones optimizadas del algoritmo (conocidas como variantes de *Lloyd‚Äôs algorithm* o *Elkan‚Äôs algorithm*). Estas implementaciones est√°n escritas en C/C++ y aprovechan estructuras de datos eficientes para minimizar los c√°lculos de distancia, reduciendo el tiempo de ejecuci√≥n.\n",
        "\n",
        "- **Vectorizaci√≥n y C√°lculo en Bloque:**  \n",
        "  Muchas operaciones (como la asignaci√≥n de puntos a centroides) se realizan en forma vectorizada, usando *NumPy* u otras librer√≠as de √°lgebra lineal, lo que aprovecha la velocidad de operaciones a nivel de bajo nivel (SIMD, paralelismo, etc.).\n",
        "\n",
        "- **Heur√≠sticas de Inicializaci√≥n (k-means++):**  \n",
        "  Aunque el ejemplo usa inicializaci√≥n aleatoria, en la pr√°ctica se suele usar *k-means++* para elegir centroides iniciales ‚Äúinteligentemente‚Äù. Esto suele acelerar la convergencia y mejorar la calidad de los clusters.\n",
        "\n",
        "- **Reducci√≥n de C√°lculos Innecesarios:**  \n",
        "  Algunas implementaciones evitan recalcular distancias para puntos que se sabe que no cambiar√°n de cluster en la siguiente iteraci√≥n, acelerando as√≠ la convergencia.\n",
        "\n",
        "En conjunto, estos factores hacen que K-means, aun siendo un algoritmo iterativo, **tienda a converger r√°pidamente** y a encontrar clusters √∫tiles en un n√∫mero relativamente bajo de pasos."
      ],
      "metadata": {
        "id": "6W1qwdlMuWBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualizar_iteraciones(n_iteraciones):\n",
        "    plt.figure(figsize=(15, 4))\n",
        "\n",
        "    for i in range(n_iteraciones):\n",
        "        # Ejecutamos K-means con (i+1) iteraciones\n",
        "        km = KMeans(n_clusters=3, max_iter=i+1, init='random', n_init=1)\n",
        "        km.fit(X)\n",
        "\n",
        "        plt.subplot(1, n_iteraciones, i+1)\n",
        "        plt.scatter(X[:, 0], X[:, 1], c=km.labels_, cmap='viridis', s=30)\n",
        "        plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n",
        "                    marker='X', s=100, c='red')\n",
        "        plt.title(f'Iteraci√≥n {i+1}')\n",
        "    plt.tight_layout()\n",
        "\n",
        "visualizar_iteraciones(3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d2UPtq4VuRQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìâ Paso 6: M√©todo del Codo\n",
        "Utilizamos el m√©todo del codo para determinar el n√∫mero √≥ptimo de clusters.\n",
        "Calculamos la inercia (la suma de las distancias al cuadrado entre cada punto y su centroide) para distintos valores de k.\n"
      ],
      "metadata": {
        "id": "NnkYMG5fyoht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inercias = []\n",
        "rang_k = range(1, 10)\n",
        "\n",
        "for k in rang_k:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X)\n",
        "    inercias.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(rang_k, inercias, 'bo-')\n",
        "plt.xlabel('N√∫mero de Clusters (k)')\n",
        "plt.ylabel('Inercia')\n",
        "plt.title('M√©todo del Codo')\n",
        "plt.xticks(rang_k)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HovvS_YWueUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el **M√©todo del Codo**, se calcula la *inercia* (o suma de distancias al cuadrado de cada punto a su centroide) para distintos valores de $k$. El objetivo es encontrar un punto en la gr√°fica donde a√±adir m√°s clusters deje de reducir significativamente la inercia, es decir, donde la curva ‚Äúse doble‚Äù y la disminuci√≥n de inercia empiece a ser menos pronunciada.\n",
        "\n",
        "Observando la gr√°fica adjunta:\n",
        "\n",
        "1. **Dr√°stica ca√≠da al principio (de $k=1$ a $k=3$)**  \n",
        "   - Cuando $k$ pasa de 1 a 2 y luego a 3, la inercia baja de forma muy notable. Esto indica que el agrupamiento est√° mejorando sustancialmente al aumentar el n√∫mero de clusters en esas primeras etapas.\n",
        "\n",
        "2. **Punto de Inflexi√≥n alrededor de $k=3$**  \n",
        "   - Despu√©s de $k=3$, la reducci√≥n en la inercia es cada vez menor. El salto de inercia entre $k=3$ y $k=4$ es m√°s leve que los saltos anteriores.  \n",
        "   - Ese ‚Äúdoble‚Äù o ‚Äúcodo‚Äù que se aprecia en la curva alrededor de $k=3$ es la se√±al de que, a partir de ah√≠, a√±adir m√°s clusters ya no aporta una mejora tan significativa en la compactaci√≥n de los grupos.\n",
        "\n",
        "3. **Interpretaci√≥n Pr√°ctica**  \n",
        "   - Con $k=3$, se logra un buen equilibrio entre complejidad (tener m√°s clusters) y calidad de la agrupaci√≥n (baja inercia).  \n",
        "   - Si se escogen m√°s clusters (por ejemplo, 4, 5, etc.), la inercia seguir√° bajando, pero la ganancia es mucho menor comparada con el salto que obtienes al pasar de 2 a 3.  \n",
        "   - En muchos casos de uso, la elecci√≥n de un $k\\ m√°s alto puede significar una sobresegmentaci√≥n de los datos (clusters demasiado peque√±os o menos interpretables).\n",
        "\n",
        "4. **Limitaciones**  \n",
        "   - El m√©todo del codo es un **criterio heur√≠stico**. No siempre el ‚Äúcodo‚Äù est√° perfectamente definido. Aun as√≠, en la gr√°fica mostrada, el codo es bastante claro en $k=3$.  \n",
        "   - Se recomienda complementar con otros m√©todos (como el √≠ndice de silhouette) o con un criterio basado en el contexto de los datos para validar la elecci√≥n de $k$.\n",
        "\n",
        "En resumen, **elegir $k=3$** en este caso se justifica porque la inercia desciende marcadamente hasta ese punto y, a partir de ah√≠, la mejora adicional es mucho m√°s peque√±a. Esto indica que **3 clusters** describen razonablemente bien la estructura de los datos sin a√±adir complejidad innecesaria."
      ],
      "metadata": {
        "id": "kuuP4RX0zTsr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8J5Eh1fv5RK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}