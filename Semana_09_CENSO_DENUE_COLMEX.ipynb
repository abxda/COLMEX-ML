{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/COLMEX-ML/blob/main/Semana_09_CENSO_DENUE_COLMEX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2UKix7dt16x"
      },
      "outputs": [],
      "source": [
        "#https://drive.google.com/file/d/1LVPNaUxto31HE-UQIO1-4l6XPER9Ry5l/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1O_GKDVQSoBAEuHjCMHMkknDxSuZd3i_A/view?usp=sharing\n",
        "# Instalar gdown si no está disponible\n",
        "#!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyarrow geopandas"
      ],
      "metadata": {
        "id": "odsV7HFJwi9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hobFSYQkoB6P"
      },
      "outputs": [],
      "source": [
        "\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely import wkb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2Wv1NMJumnk"
      },
      "outputs": [],
      "source": [
        "# Descargar el archivo usando el ID de Google Drive\n",
        "!gdown --id 1LVPNaUxto31HE-UQIO1-4l6XPER9Ry5l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvXGaQLEu0FE"
      },
      "outputs": [],
      "source": [
        "!gdown --id 1O_GKDVQSoBAEuHjCMHMkknDxSuZd3i_A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkYutjZNvcFn"
      },
      "outputs": [],
      "source": [
        "!ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5k1itdjvhdm"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos\n",
        "db_path = \"/content/datos_censo_nacional_s9.duckdb\"\n",
        "conn = duckdb.connect(db_path)\n",
        "\n",
        "# Obtener listado de tablas\n",
        "tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
        "\n",
        "# Generar reporte\n",
        "reporte = {}\n",
        "for table in tables:\n",
        "    table_name = table[0]\n",
        "    # Obtener metadatos de columnas\n",
        "    columns = conn.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
        "    # Almacenar nombre y tipo de cada columna\n",
        "    reporte[table_name] = [(col[1], col[2]) for col in columns]\n",
        "\n",
        "# Mostrar resultados en formato legible\n",
        "for tabla, columnas in reporte.items():\n",
        "    print(f\"\\n[ Tabla: {tabla} ]\")\n",
        "    print(\"--------------------\")\n",
        "    for columna in columnas:\n",
        "        print(f\"- {columna[0]} ({columna[1]})\")\n",
        "    print(\"--------------------\")\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFarW39awWcI"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos\n",
        "db_path = \"/content/denue_total_4.duckdb\"\n",
        "conn = duckdb.connect(db_path)\n",
        "\n",
        "# Obtener listado de tablas\n",
        "tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
        "\n",
        "# Generar reporte\n",
        "reporte = {}\n",
        "for table in tables:\n",
        "    table_name = table[0]\n",
        "    # Obtener metadatos de columnas\n",
        "    columns = conn.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
        "    # Almacenar nombre y tipo de cada columna\n",
        "    reporte[table_name] = [(col[1], col[2]) for col in columns]\n",
        "\n",
        "# Mostrar resultados en formato legible\n",
        "for tabla, columnas in reporte.items():\n",
        "    print(f\"\\n[ Tabla: {tabla} ]\")\n",
        "    print(\"--------------------\")\n",
        "    for columna in columnas:\n",
        "        print(f\"- {columna[0]} ({columna[1]})\")\n",
        "    print(\"--------------------\")\n",
        "\n",
        "\n",
        "# Verificar creación del nuevo archivo\n",
        "print(\"\\nBase de datos creada:\")\n",
        "!ls -lh {db_path}\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa9h6AoVwhC8"
      },
      "outputs": [],
      "source": [
        "# Crear nueva base de datos\n",
        "new_db_path = \"/content/denue_total_est_per_ocu_final_5.duckdb\"\n",
        "conn = duckdb.connect(new_db_path)\n",
        "\n",
        "# Cargar extensión espacial\n",
        "conn.install_extension(\"spatial\")\n",
        "conn.load_extension(\"spatial\")\n",
        "\n",
        "# Crear tabla compatible\n",
        "conn.execute(f\"\"\"\n",
        "ATTACH DATABASE '/content/denue_total_4.duckdb' AS source_db;\n",
        "\n",
        "CREATE TABLE denue_est_per_ocu AS\n",
        "SELECT\n",
        "    id,\n",
        "    clee,\n",
        "    SUBSTRING(codigo_act, 1, 2) AS codigo_act_2c,\n",
        "    codigo_act,\n",
        "    LOWER(nom_estab) AS nom_estab,\n",
        "    cve_ent,\n",
        "    LOWER(entidad) AS entidad,\n",
        "    cve_mun,\n",
        "    LOWER(municipio) AS municipio,\n",
        "    cve_loc,\n",
        "    LOWER(localidad) AS localidad,\n",
        "    CASE\n",
        "        WHEN per_ocu LIKE '%0 a 5 personas%' THEN 2.5\n",
        "        WHEN per_ocu LIKE '%6 a 10 personas%' THEN 8\n",
        "        WHEN per_ocu LIKE '%11 a 30 personas%' THEN 20.5\n",
        "        WHEN per_ocu LIKE '%31 a 50 personas%' THEN 40.5\n",
        "        WHEN per_ocu LIKE '%51 a 100 personas%' THEN 75.5\n",
        "        WHEN per_ocu LIKE '%101 a 250 personas%' THEN 175.5\n",
        "        WHEN per_ocu LIKE '%251 y más personas%' THEN 350\n",
        "        ELSE 1.0\n",
        "    END AS est_per_ocu,\n",
        "    geometry\n",
        "FROM source_db.denue;\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# Verificar la nueva tabla\n",
        "result = conn.execute(\"PRAGMA table_info(denue_est_per_ocu)\").fetchall()\n",
        "print(\"\\nEsquema de la nueva tabla:\")\n",
        "for col in result:\n",
        "    print(f\"- {col[1]} ({col[2]})\")\n",
        "\n",
        "# Verificar creación del nuevo archivo\n",
        "print(\"\\nBase de datos creada:\")\n",
        "!ls -lh {new_db_path}\n",
        "\n",
        "# Verificar tablas en la nueva base de datos\n",
        "tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
        "print(\"\\nTablas en la nueva base de datos:\")\n",
        "for table in tables:\n",
        "    print(f\"- {table[0]}\")\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEb8EK00Q9dk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ruta al archivo DuckDB (la tabla 'nacional' se creará dentro de este archivo)\n",
        "db_path = \"/content/denue_total_est_per_ocu_final_5.duckdb\"\n",
        "conn = duckdb.connect(db_path)\n",
        "\n",
        "# Instalar y cargar la extensión espacial (si aún no se hizo)\n",
        "conn.execute(\"INSTALL spatial;\")\n",
        "conn.execute(\"LOAD spatial;\")\n",
        "\n",
        "# Crear la tabla 'nacional' directamente en el archivo DuckDB\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS nacional;\n",
        "CREATE TABLE nacional AS\n",
        "WITH\n",
        "  -- Extraer OXXOs\n",
        "  oxxos AS (\n",
        "    SELECT\n",
        "      1 AS klass,\n",
        "      id,\n",
        "      codigo_act,\n",
        "      codigo_act_2c,\n",
        "      clee,\n",
        "      LOWER(nom_estab) AS nom_estab,\n",
        "      cve_ent,\n",
        "      est_per_ocu as personal,\n",
        "      geometry\n",
        "    FROM denue_est_per_ocu\n",
        "    WHERE codigo_act = '462112'\n",
        "      AND lower(nom_estab) LIKE '%oxxo%'\n",
        "      AND lower(nom_estab) NOT LIKE '%distribuc%'\n",
        "  ),\n",
        "  -- Contar el número de OXXOs\n",
        "  num_oxxos AS (\n",
        "    SELECT count(*) AS n FROM oxxos\n",
        "  ),\n",
        "  -- Extraer tiendas de abarrotes\n",
        "  abarrotes AS (\n",
        "    SELECT\n",
        "      0 AS klass,\n",
        "      id,\n",
        "      codigo_act,\n",
        "      codigo_act_2c,\n",
        "      clee,\n",
        "      LOWER(nom_estab) AS nom_estab,\n",
        "      cve_ent,\n",
        "      est_per_ocu as personal,\n",
        "      geometry\n",
        "    FROM denue_est_per_ocu\n",
        "    WHERE codigo_act = '461110'\n",
        "  ),\n",
        "  -- Seleccionar aleatoriamente tantas tiendas de abarrotes como OXXOs existen\n",
        "  abarrotes_sample AS (\n",
        "    SELECT *\n",
        "    FROM abarrotes\n",
        "    ORDER BY random()\n",
        "    LIMIT (SELECT n FROM num_oxxos)\n",
        "  )\n",
        "-- Unir ambos conjuntos y mezclarlos aleatoriamente\n",
        "SELECT *\n",
        "FROM oxxos\n",
        "UNION ALL\n",
        "SELECT *\n",
        "FROM abarrotes_sample;\n",
        "\"\"\")\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuDDRCEPSC8U"
      },
      "outputs": [],
      "source": [
        "# Ruta al archivo DuckDB (la tabla 'nacional' se creará dentro de este archivo)\n",
        "db_path = \"/content/denue_total_est_per_ocu_final_5.duckdb\"\n",
        "conn = duckdb.connect(db_path)\n",
        "\n",
        "# Instalar y cargar la extensión espacial (si aún no se hizo)\n",
        "conn.execute(\"INSTALL spatial;\")\n",
        "conn.execute(\"LOAD spatial;\")\n",
        "# Mostrar una muestra de algunos registros de la tabla 'nacional'\n",
        "sample = conn.execute(\"SELECT * FROM denue_est_per_ocu order by random() LIMIT 100\").fetch_df()\n",
        "\n",
        "conn.close()\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbDboH-fMUg1"
      },
      "outputs": [],
      "source": [
        "# Conectar a las bases de datos y configurar extensiones\n",
        "conn = duckdb.connect('/content/denue_total_est_per_ocu_final_5.duckdb')\n",
        "conn.execute(\"INSTALL spatial; LOAD spatial;\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiQHKdjxMUjl"
      },
      "outputs": [],
      "source": [
        "# 3. Crear la tabla 'nacional_buffer_100' usando el buffer de 0.000898 grados (aproximadamente 100 m)\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS nacional_buffer_100;\n",
        "CREATE TABLE nacional_buffer_100 AS\n",
        "SELECT *,\n",
        "       ST_Buffer(geometry, 0.000898) AS buffer_100\n",
        "FROM nacional;\n",
        "\"\"\")\n",
        "\n",
        "# 4. Crear la tabla 'nacional_buffer_500' usando el buffer de 0.00449 grados (aproximadamente 500 m)\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS nacional_buffer_500;\n",
        "CREATE TABLE nacional_buffer_500 AS\n",
        "SELECT *,\n",
        "       ST_Buffer(geometry, 0.00449) AS buffer_500\n",
        "FROM nacional;\n",
        "\"\"\")\n",
        "\n",
        "# 5. Agregar (sumar) est_per_ocu para los puntos DENUE dentro del buffer de 100 metros\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS agg_100;\n",
        "CREATE TABLE agg_100 AS\n",
        "SELECT\n",
        "    n.id AS nacional_id,\n",
        "    SUM(d.est_per_ocu) AS epo_100\n",
        "FROM nacional_buffer_100 n\n",
        "JOIN denue_est_per_ocu d ON ST_Intersects(n.buffer_100, d.geometry)\n",
        "GROUP BY n.id;\n",
        "\"\"\")\n",
        "\n",
        "# 6. Agregar (sumar) est_per_ocu para los puntos DENUE dentro del buffer de 500 metros\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS agg_500;\n",
        "CREATE TABLE agg_500 AS\n",
        "SELECT\n",
        "    n.id AS nacional_id,\n",
        "    SUM(d.est_per_ocu) AS epo_500\n",
        "FROM nacional_buffer_500 n\n",
        "JOIN denue_est_per_ocu d ON ST_Intersects(n.buffer_500, d.geometry)\n",
        "GROUP BY n.id;\n",
        "\"\"\")\n",
        "\n",
        "# 7. Crear la tabla final 'nacional_final' uniendo la tabla 'nacional_proj' con las sumas agregadas\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS nacional_final;\n",
        "CREATE TABLE nacional_final AS\n",
        "SELECT\n",
        "    n.*,\n",
        "    COALESCE(a.epo_100, 0) AS epo_100,\n",
        "    COALESCE(b.epo_500, 0) AS epo_500\n",
        "FROM nacional n\n",
        "LEFT JOIN agg_100 a ON n.id = a.nacional_id\n",
        "LEFT JOIN agg_500 b ON n.id = b.nacional_id;\n",
        "\"\"\")\n",
        "\n",
        "# Mostrar una muestra de algunos registros de 'nacional_final' sin cargar todos los datos en Pandas\n",
        "sample_records = conn.execute(\"SELECT * FROM nacional_final LIMIT 10\").fetchall()\n",
        "print(\"Muestra de registros de 'nacional_final':\")\n",
        "for rec in sample_records:\n",
        "    print(rec)\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2tkhzg8OJTC"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos\n",
        "conn = duckdb.connect('/content/denue_total_est_per_ocu_final_5.duckdb')\n",
        "\n",
        "# Ejecutar la consulta para obtener 10 registros de la tabla 'nacional'\n",
        "df_nacional = conn.execute(\"SELECT * FROM nacional_final LIMIT 10\").df()\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "print(\"Muestra de registros de la tabla 'nacional':\")\n",
        "print(df_nacional)\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mux210KRMUmM"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos\n",
        "conn = duckdb.connect('/content/denue_total_est_per_ocu_final_5.duckdb')\n",
        "conn.execute(\"INSTALL spatial; LOAD spatial;\")\n",
        "\n",
        "# --- Paso A: Agregar personal ocupado por actividad (2 caracteres) en buffers de 100 m ---\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS agg_act_100;\n",
        "CREATE TABLE agg_act_100 AS\n",
        "SELECT\n",
        "    n.id AS nacional_id,\n",
        "    d.codigo_act_2c,\n",
        "    SUM(d.est_per_ocu) AS sum_est_per_ocu\n",
        "FROM nacional_buffer_100 n\n",
        "JOIN denue_est_per_ocu d ON ST_Intersects(n.buffer_100, d.geometry)\n",
        "GROUP BY n.id, d.codigo_act_2c;\n",
        "\"\"\")\n",
        "\n",
        "# --- Paso B: Agregar personal ocupado por actividad (2 caracteres) en buffers de 500 m ---\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS agg_act_500;\n",
        "CREATE TABLE agg_act_500 AS\n",
        "SELECT\n",
        "    n.id AS nacional_id,\n",
        "    d.codigo_act_2c,\n",
        "    SUM(d.est_per_ocu) AS sum_est_per_ocu\n",
        "FROM nacional_buffer_500 n\n",
        "JOIN denue_est_per_ocu d ON ST_Intersects(n.buffer_500, d.geometry)\n",
        "GROUP BY  n.id, d.codigo_act_2c;\n",
        "\"\"\")\n",
        "\n",
        "# --- Paso C: Crear tabla final para buffers de 100 m pivotando la agregación por actividad ---\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS nacional_final_act_100;\n",
        "CREATE TABLE nacional_final_act_100 AS\n",
        "SELECT\n",
        "    n.id, n.klass, n.clee, n.nom_estab, n.cve_ent, n.personal, n.geometry,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '51' THEN a.sum_est_per_ocu ELSE 0 END) AS act_51_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '54' THEN a.sum_est_per_ocu ELSE 0 END) AS act_54_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '11' THEN a.sum_est_per_ocu ELSE 0 END) AS act_11_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '22' THEN a.sum_est_per_ocu ELSE 0 END) AS act_22_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '52' THEN a.sum_est_per_ocu ELSE 0 END) AS act_52_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '71' THEN a.sum_est_per_ocu ELSE 0 END) AS act_71_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '43' THEN a.sum_est_per_ocu ELSE 0 END) AS act_43_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '31' THEN a.sum_est_per_ocu ELSE 0 END) AS act_31_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '61' THEN a.sum_est_per_ocu ELSE 0 END) AS act_61_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '46' THEN a.sum_est_per_ocu ELSE 0 END) AS act_46_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '23' THEN a.sum_est_per_ocu ELSE 0 END) AS act_23_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '55' THEN a.sum_est_per_ocu ELSE 0 END) AS act_55_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '93' THEN a.sum_est_per_ocu ELSE 0 END) AS act_93_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '53' THEN a.sum_est_per_ocu ELSE 0 END) AS act_53_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '81' THEN a.sum_est_per_ocu ELSE 0 END) AS act_81_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '33' THEN a.sum_est_per_ocu ELSE 0 END) AS act_33_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '48' THEN a.sum_est_per_ocu ELSE 0 END) AS act_48_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '32' THEN a.sum_est_per_ocu ELSE 0 END) AS act_32_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '56' THEN a.sum_est_per_ocu ELSE 0 END) AS act_56_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '49' THEN a.sum_est_per_ocu ELSE 0 END) AS act_49_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '62' THEN a.sum_est_per_ocu ELSE 0 END) AS act_62_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '21' THEN a.sum_est_per_ocu ELSE 0 END) AS act_21_100,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '72' THEN a.sum_est_per_ocu ELSE 0 END) AS act_72_100\n",
        "FROM nacional n\n",
        "LEFT JOIN agg_act_100 a ON n.id = a.nacional_id\n",
        "GROUP BY n.id, n.klass, n.clee, n.nom_estab, n.cve_ent, n.personal, n.geometry;\n",
        "\"\"\")\n",
        "\n",
        "# --- Paso D: Crear tabla final para buffers de 500 m pivotando la agregación por actividad ---\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS nacional_final_act_500;\n",
        "CREATE TABLE nacional_final_act_500 AS\n",
        "SELECT\n",
        "    n.id, n.klass, n.clee, n.nom_estab, n.cve_ent, n.personal, n.geometry,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '51' THEN a.sum_est_per_ocu ELSE 0 END) AS act_51_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '54' THEN a.sum_est_per_ocu ELSE 0 END) AS act_54_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '11' THEN a.sum_est_per_ocu ELSE 0 END) AS act_11_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '22' THEN a.sum_est_per_ocu ELSE 0 END) AS act_22_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '52' THEN a.sum_est_per_ocu ELSE 0 END) AS act_52_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '71' THEN a.sum_est_per_ocu ELSE 0 END) AS act_71_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '43' THEN a.sum_est_per_ocu ELSE 0 END) AS act_43_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '31' THEN a.sum_est_per_ocu ELSE 0 END) AS act_31_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '61' THEN a.sum_est_per_ocu ELSE 0 END) AS act_61_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '46' THEN a.sum_est_per_ocu ELSE 0 END) AS act_46_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '23' THEN a.sum_est_per_ocu ELSE 0 END) AS act_23_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '55' THEN a.sum_est_per_ocu ELSE 0 END) AS act_55_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '93' THEN a.sum_est_per_ocu ELSE 0 END) AS act_93_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '53' THEN a.sum_est_per_ocu ELSE 0 END) AS act_53_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '81' THEN a.sum_est_per_ocu ELSE 0 END) AS act_81_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '33' THEN a.sum_est_per_ocu ELSE 0 END) AS act_33_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '48' THEN a.sum_est_per_ocu ELSE 0 END) AS act_48_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '32' THEN a.sum_est_per_ocu ELSE 0 END) AS act_32_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '56' THEN a.sum_est_per_ocu ELSE 0 END) AS act_56_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '49' THEN a.sum_est_per_ocu ELSE 0 END) AS act_49_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '62' THEN a.sum_est_per_ocu ELSE 0 END) AS act_62_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '21' THEN a.sum_est_per_ocu ELSE 0 END) AS act_21_500,\n",
        "    MAX(CASE WHEN a.codigo_act_2c = '72' THEN a.sum_est_per_ocu ELSE 0 END) AS act_72_500\n",
        "FROM nacional n\n",
        "LEFT JOIN agg_act_500 a ON n.id = a.nacional_id\n",
        "GROUP BY n.id, n.klass, n.clee, n.nom_estab, n.cve_ent, n.personal, n.geometry;\n",
        "\"\"\")\n",
        "\n",
        "# Mostrar una muestra de registros de la tabla final para 100 m\n",
        "sample_100 = conn.execute(\"SELECT * FROM nacional_final_act_100 LIMIT 10\").fetchall()\n",
        "print(\"Muestra de registros de 'nacional_final_act_100':\")\n",
        "for rec in sample_100:\n",
        "    print(rec)\n",
        "\n",
        "# Mostrar una muestra de registros de la tabla final para 500 m\n",
        "sample_500 = conn.execute(\"SELECT * FROM nacional_final_act_500 LIMIT 10\").fetchall()\n",
        "print(\"\\nMuestra de registros de 'nacional_final_act_500':\")\n",
        "for rec in sample_500:\n",
        "    print(rec)\n",
        "\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE692zNNMUo0"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos\n",
        "conn = duckdb.connect('/content/denue_total_est_per_ocu_final_5.duckdb')\n",
        "\n",
        "# Ejecutar la consulta para obtener 10 registros de la tabla 'nacional'\n",
        "df_nacional = conn.execute(\"SELECT * FROM nacional_final_act_500 LIMIT 10\").df()\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "print(\"Muestra de registros de la tabla 'nacional':\")\n",
        "print(df_nacional)\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moCGzzudMUrV"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos\n",
        "conn = duckdb.connect('/content/denue_total_est_per_ocu_final_5.duckdb')\n",
        "conn.execute(\"INSTALL spatial; LOAD spatial;\")\n",
        "\n",
        "# Crear la tabla final completa uniendo nacional_final con las tablas pivotadas para 100 m y 500 m\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS nacional_final_completa;\n",
        "CREATE TABLE nacional_final_completa AS\n",
        "SELECT\n",
        "    n.*,\n",
        "    -- Variables de buffers de 100 m\n",
        "    a.act_51_100, a.act_54_100, a.act_11_100, a.act_22_100, a.act_52_100, a.act_71_100,\n",
        "    a.act_43_100, a.act_31_100, a.act_61_100, a.act_46_100, a.act_23_100, a.act_55_100,\n",
        "    a.act_93_100, a.act_53_100, a.act_81_100, a.act_33_100, a.act_48_100, a.act_32_100,\n",
        "    a.act_56_100, a.act_49_100, a.act_62_100, a.act_21_100, a.act_72_100,\n",
        "    -- Variables de buffers de 500 m\n",
        "    b.act_51_500, b.act_54_500, b.act_11_500, b.act_22_500, b.act_52_500, b.act_71_500,\n",
        "    b.act_43_500, b.act_31_500, b.act_61_500, b.act_46_500, b.act_23_500, b.act_55_500,\n",
        "    b.act_93_500, b.act_53_500, b.act_81_500, b.act_33_500, b.act_48_500, b.act_32_500,\n",
        "    b.act_56_500, b.act_49_500, b.act_62_500, b.act_21_500, b.act_72_500\n",
        "FROM nacional_final n\n",
        "LEFT JOIN nacional_final_act_100 a ON n.id = a.id\n",
        "LEFT JOIN nacional_final_act_500 b ON n.id = b.id;\n",
        "\"\"\")\n",
        "\n",
        "# Mostrar una muestra de registros de la tabla completa en un DataFrame\n",
        "df_completa = conn.execute(\"SELECT * FROM nacional_final_completa LIMIT 10\").df()\n",
        "print(\"Muestra de registros de 'nacional_final_completa':\")\n",
        "print(df_completa)\n",
        "\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qF8iXcnMUt1"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos\n",
        "conn = duckdb.connect('/content/denue_total_est_per_ocu_final_5.duckdb')\n",
        "\n",
        "# Cargar la tabla 'nacional_final_completa' en un DataFrame\n",
        "df_nacional_final_completa = conn.execute(\"SELECT * FROM nacional_final_completa\").df()\n",
        "\n",
        "# Mostrar los primeros registros\n",
        "print(\"Muestra de registros de 'nacional_final_completa':\")\n",
        "print(df_nacional_final_completa.head())\n",
        "\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpVfyWuOMUwM"
      },
      "outputs": [],
      "source": [
        "df_nacional_final_completa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ22dnG4MUys"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos y extraer los datos con la geometría en WKB\n",
        "conn = duckdb.connect('/content/denue_total_est_per_ocu_final_5.duckdb')\n",
        "conn.execute(\"INSTALL spatial; LOAD spatial;\")\n",
        "\n",
        "df = conn.execute(\"\"\"\n",
        "    SELECT\n",
        "        *,\n",
        "        ST_AsWKB(geometry) AS geom_wkb\n",
        "    FROM nacional_final_completa\n",
        "\"\"\").df()\n",
        "conn.close()\n",
        "\n",
        "# Función segura para cargar la geometría a partir de WKB\n",
        "def safe_wkb_load(x):\n",
        "    # Verificar si x es del tipo adecuado (bytes o bytearray)\n",
        "    if isinstance(x, (bytes, bytearray)):\n",
        "        try:\n",
        "            return wkb.loads(x)\n",
        "        except Exception as e:\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Aplicar la función a la columna 'geom_wkb'\n",
        "df['geom'] = df['geom_wkb'].apply(safe_wkb_load)\n",
        "\n",
        "# Eliminar las columnas originales 'geometry' y 'geom_wkb'\n",
        "df = df.drop(columns=['geometry', 'geom_wkb'])\n",
        "\n",
        "# Crear el GeoDataFrame usando la columna 'geom' como geometría activa\n",
        "gdf = gpd.GeoDataFrame(df, geometry='geom', crs=\"EPSG:4326\")\n",
        "\n",
        "# Exportar a GeoPackage\n",
        "gdf.to_file(\"nacional_final_completa.gpkg\", driver=\"GPKG\")\n",
        "\n",
        "print(\"GeoPackage 'nacional_final_completa.gpkg' creado exitosamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCzxmcofMU1N"
      },
      "outputs": [],
      "source": [
        "gdf.to_parquet(\"nacional_final_completa.geoparquet\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.to_file(\"nacional_final_completa.shp\")"
      ],
      "metadata": {
        "id": "gNCM3BG-xN6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZc-0FEZMU38"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos\n",
        "db_path = \"/content/datos_censo_nacional_s9.duckdb\"\n",
        "conn = duckdb.connect(db_path)\n",
        "\n",
        "# Obtener listado de tablas\n",
        "tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
        "\n",
        "print(\"Tablas y sus campos:\")\n",
        "\n",
        "# Recorrer cada tabla y obtener sus columnas usando PRAGMA table_info\n",
        "for table in tables:\n",
        "    table_name = table[0]\n",
        "    print(f\"\\nTabla: {table_name}\")\n",
        "    print(\"-\" * (len(table_name) + 8))\n",
        "    columns = conn.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
        "    for col in columns:\n",
        "        print(f\"- {col[1]} ({col[2]})\")\n",
        "\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ2Th1kpMU6d"
      },
      "outputs": [],
      "source": [
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJqNUBE_JKbW"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos destino (donde se crearán las tablas de cálculo)\n",
        "conn = duckdb.connect('/content/denue_total_est_per_ocu_final_5.duckdb')\n",
        "conn.execute(\"INSTALL spatial; LOAD spatial;\")\n",
        "# --- Paso 1: Crear la tabla de centroides a partir de censo_geo_int ---\n",
        "# Se adjunta la base de datos fuente (datos_censo_nacional_s9.duckdb)\n",
        "# Verificar si 'src_db' ya está adjunto usando SHOW DATABASES\n",
        "attached = conn.execute(\"SHOW DATABASES;\").fetchall()\n",
        "if not any(row[0] == 'src_db' for row in attached):\n",
        "    conn.execute(\"ATTACH DATABASE '/content/datos_censo_nacional_s9.duckdb' AS src_db;\")\n",
        "else:\n",
        "    print(\"'src_db' ya está adjunto.\")\n",
        "\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS censo_geo_int_centroid;\n",
        "CREATE TABLE censo_geo_int_centroid AS\n",
        "SELECT\n",
        "    COALESCE(POBTOT, 0) AS POBTOT,\n",
        "    COALESCE(POBFEM, 0) AS POBFEM,\n",
        "    COALESCE(POBMAS, 0) AS POBMAS,\n",
        "\n",
        "    COALESCE(P_0A2, 0) AS P_0A2,\n",
        "    COALESCE(P_0A2_F, 0) AS P_0A2_F,\n",
        "    COALESCE(P_0A2_M, 0) AS P_0A2_M,\n",
        "    COALESCE(P_3YMAS, 0) AS P_3YMAS,\n",
        "    COALESCE(P_3YMAS_F, 0) AS P_3YMAS_F,\n",
        "    COALESCE(P_3YMAS_M, 0) AS P_3YMAS_M,\n",
        "    COALESCE(P_5YMAS, 0) AS P_5YMAS,\n",
        "    COALESCE(P_5YMAS_F, 0) AS P_5YMAS_F,\n",
        "    COALESCE(P_5YMAS_M, 0) AS P_5YMAS_M,\n",
        "    COALESCE(P_12YMAS, 0) AS P_12YMAS,\n",
        "    COALESCE(P_12YMAS_F, 0) AS P_12YMAS_F,\n",
        "    COALESCE(P_12YMAS_M, 0) AS P_12YMAS_M,\n",
        "    COALESCE(P_15YMAS, 0) AS P_15YMAS,\n",
        "    COALESCE(P_15YMAS_F, 0) AS P_15YMAS_F,\n",
        "    COALESCE(P_15YMAS_M, 0) AS P_15YMAS_M,\n",
        "    COALESCE(P_18YMAS, 0) AS P_18YMAS,\n",
        "    COALESCE(P_18YMAS_F, 0) AS P_18YMAS_F,\n",
        "    COALESCE(P_18YMAS_M, 0) AS P_18YMAS_M,\n",
        "    COALESCE(P_3A5, 0) AS P_3A5,\n",
        "    COALESCE(P_3A5_F, 0) AS P_3A5_F,\n",
        "    COALESCE(P_3A5_M, 0) AS P_3A5_M,\n",
        "    COALESCE(P_6A11, 0) AS P_6A11,\n",
        "    COALESCE(P_6A11_F, 0) AS P_6A11_F,\n",
        "    COALESCE(P_6A11_M, 0) AS P_6A11_M,\n",
        "    COALESCE(P_8A14, 0) AS P_8A14,\n",
        "    COALESCE(P_8A14_F, 0) AS P_8A14_F,\n",
        "    COALESCE(P_8A14_M, 0) AS P_8A14_M,\n",
        "    COALESCE(P_12A14, 0) AS P_12A14,\n",
        "    COALESCE(P_12A14_F, 0) AS P_12A14_F,\n",
        "    COALESCE(P_12A14_M, 0) AS P_12A14_M,\n",
        "    COALESCE(P_15A17, 0) AS P_15A17,\n",
        "    COALESCE(P_15A17_F, 0) AS P_15A17_F,\n",
        "    COALESCE(P_15A17_M, 0) AS P_15A17_M,\n",
        "    COALESCE(P_18A24, 0) AS P_18A24,\n",
        "    COALESCE(P_18A24_F, 0) AS P_18A24_F,\n",
        "    COALESCE(P_18A24_M, 0) AS P_18A24_M,\n",
        "    COALESCE(P_15A49_F, 0) AS P_15A49_F,\n",
        "    COALESCE(P_60YMAS, 0) AS P_60YMAS,\n",
        "    COALESCE(P_60YMAS_F, 0) AS P_60YMAS_F,\n",
        "    COALESCE(P_60YMAS_M, 0) AS P_60YMAS_M,\n",
        "    COALESCE(REL_H_M, 0) AS REL_H_M,\n",
        "    COALESCE(POB0_14, 0) AS POB0_14,\n",
        "    COALESCE(POB15_64, 0) AS POB15_64,\n",
        "    COALESCE(POB65_MAS, 0) AS POB65_MAS,\n",
        "    COALESCE(PROM_HNV, 0) AS PROM_HNV,\n",
        "    COALESCE(PNACENT, 0) AS PNACENT,\n",
        "    COALESCE(PNACENT_F, 0) AS PNACENT_F,\n",
        "    COALESCE(PNACENT_M, 0) AS PNACENT_M,\n",
        "    COALESCE(PNACOE, 0) AS PNACOE,\n",
        "    COALESCE(PNACOE_F, 0) AS PNACOE_F,\n",
        "    COALESCE(PNACOE_M, 0) AS PNACOE_M,\n",
        "    COALESCE(PRES2015, 0) AS PRES2015,\n",
        "    COALESCE(PRES2015_F, 0) AS PRES2015_F,\n",
        "    COALESCE(PRES2015_M, 0) AS PRES2015_M,\n",
        "    COALESCE(PRESOE15, 0) AS PRESOE15,\n",
        "    COALESCE(PRESOE15_F, 0) AS PRESOE15_F,\n",
        "    COALESCE(PRESOE15_M, 0) AS PRESOE15_M,\n",
        "    COALESCE(P3YM_HLI, 0) AS P3YM_HLI,\n",
        "    COALESCE(P3YM_HLI_F, 0) AS P3YM_HLI_F,\n",
        "    COALESCE(P3YM_HLI_M, 0) AS P3YM_HLI_M,\n",
        "    COALESCE(P3HLINHE, 0) AS P3HLINHE,\n",
        "    COALESCE(P3HLINHE_F, 0) AS P3HLINHE_F,\n",
        "    COALESCE(P3HLINHE_M, 0) AS P3HLINHE_M,\n",
        "    COALESCE(P3HLI_HE, 0) AS P3HLI_HE,\n",
        "    COALESCE(P3HLI_HE_F, 0) AS P3HLI_HE_F,\n",
        "    COALESCE(P3HLI_HE_M, 0) AS P3HLI_HE_M,\n",
        "    COALESCE(P5_HLI, 0) AS P5_HLI,\n",
        "    COALESCE(P5_HLI_NHE, 0) AS P5_HLI_NHE,\n",
        "    COALESCE(P5_HLI_HE, 0) AS P5_HLI_HE,\n",
        "    COALESCE(PHOG_IND, 0) AS PHOG_IND,\n",
        "    COALESCE(POB_AFRO, 0) AS POB_AFRO,\n",
        "    COALESCE(POB_AFRO_F, 0) AS POB_AFRO_F,\n",
        "    COALESCE(POB_AFRO_M, 0) AS POB_AFRO_M,\n",
        "    COALESCE(PCON_DISC, 0) AS PCON_DISC,\n",
        "    COALESCE(PCDISC_MOT, 0) AS PCDISC_MOT,\n",
        "    COALESCE(PCDISC_VIS, 0) AS PCDISC_VIS,\n",
        "    COALESCE(PCDISC_LENG, 0) AS PCDISC_LENG,\n",
        "    COALESCE(PCDISC_AUD, 0) AS PCDISC_AUD,\n",
        "    COALESCE(PCDISC_MOT2, 0) AS PCDISC_MOT2,\n",
        "    COALESCE(PCDISC_MEN, 0) AS PCDISC_MEN,\n",
        "    COALESCE(PCON_LIMI, 0) AS PCON_LIMI,\n",
        "    COALESCE(PCLIM_CSB, 0) AS PCLIM_CSB,\n",
        "    COALESCE(PCLIM_VIS, 0) AS PCLIM_VIS,\n",
        "    COALESCE(PCLIM_HACO, 0) AS PCLIM_HACO,\n",
        "    COALESCE(PCLIM_OAUD, 0) AS PCLIM_OAUD,\n",
        "    COALESCE(PCLIM_MOT2, 0) AS PCLIM_MOT2,\n",
        "    COALESCE(PCLIM_RE_CO, 0) AS PCLIM_RE_CO,\n",
        "    COALESCE(PCLIM_PMEN, 0) AS PCLIM_PMEN,\n",
        "    COALESCE(PSIND_LIM, 0) AS PSIND_LIM,\n",
        "    COALESCE(P3A5_NOA, 0) AS P3A5_NOA,\n",
        "    COALESCE(P3A5_NOA_F, 0) AS P3A5_NOA_F,\n",
        "    COALESCE(P3A5_NOA_M, 0) AS P3A5_NOA_M,\n",
        "    COALESCE(P6A11_NOA, 0) AS P6A11_NOA,\n",
        "    COALESCE(P6A11_NOAF, 0) AS P6A11_NOAF,\n",
        "    COALESCE(P6A11_NOAM, 0) AS P6A11_NOAM,\n",
        "    COALESCE(P12A14NOA, 0) AS P12A14NOA,\n",
        "    COALESCE(P12A14NOAF, 0) AS P12A14NOAF,\n",
        "    COALESCE(P12A14NOAM, 0) AS P12A14NOAM,\n",
        "    COALESCE(P15A17A, 0) AS P15A17A,\n",
        "    COALESCE(P15A17A_F, 0) AS P15A17A_F,\n",
        "    COALESCE(P15A17A_M, 0) AS P15A17A_M,\n",
        "    COALESCE(P18A24A, 0) AS P18A24A,\n",
        "    COALESCE(P18A24A_F, 0) AS P18A24A_F,\n",
        "    COALESCE(P18A24A_M, 0) AS P18A24A_M,\n",
        "    COALESCE(P8A14AN, 0) AS P8A14AN,\n",
        "    COALESCE(P8A14AN_F, 0) AS P8A14AN_F,\n",
        "    COALESCE(P8A14AN_M, 0) AS P8A14AN_M,\n",
        "    COALESCE(P15YM_AN, 0) AS P15YM_AN,\n",
        "    COALESCE(P15YM_AN_F, 0) AS P15YM_AN_F,\n",
        "    COALESCE(P15YM_AN_M, 0) AS P15YM_AN_M,\n",
        "    COALESCE(P15YM_SE, 0) AS P15YM_SE,\n",
        "    COALESCE(P15YM_SE_F, 0) AS P15YM_SE_F,\n",
        "    COALESCE(P15YM_SE_M, 0) AS P15YM_SE_M,\n",
        "    COALESCE(P15PRI_IN, 0) AS P15PRI_IN,\n",
        "    COALESCE(P15PRI_INF, 0) AS P15PRI_INF,\n",
        "    COALESCE(P15PRI_INM, 0) AS P15PRI_INM,\n",
        "    COALESCE(P15PRI_CO, 0) AS P15PRI_CO,\n",
        "    COALESCE(P15PRI_COF, 0) AS P15PRI_COF,\n",
        "    COALESCE(P15PRI_COM, 0) AS P15PRI_COM,\n",
        "    COALESCE(P15SEC_IN, 0) AS P15SEC_IN,\n",
        "    COALESCE(P15SEC_INF, 0) AS P15SEC_INF,\n",
        "    COALESCE(P15SEC_INM, 0) AS P15SEC_INM,\n",
        "    COALESCE(P15SEC_CO, 0) AS P15SEC_CO,\n",
        "    COALESCE(P15SEC_COF, 0) AS P15SEC_COF,\n",
        "    COALESCE(P15SEC_COM, 0) AS P15SEC_COM,\n",
        "    COALESCE(P18YM_PB, 0) AS P18YM_PB,\n",
        "    COALESCE(P18YM_PB_F, 0) AS P18YM_PB_F,\n",
        "    COALESCE(P18YM_PB_M, 0) AS P18YM_PB_M,\n",
        "    COALESCE(GRAPROES, 0) AS GRAPROES,\n",
        "    COALESCE(GRAPROES_F, 0) AS GRAPROES_F,\n",
        "    COALESCE(GRAPROES_M, 0) AS GRAPROES_M,\n",
        "    COALESCE(PEA, 0) AS PEA,\n",
        "    COALESCE(PEA_F, 0) AS PEA_F,\n",
        "    COALESCE(PEA_M, 0) AS PEA_M,\n",
        "    COALESCE(PE_INAC, 0) AS PE_INAC,\n",
        "    COALESCE(PE_INAC_F, 0) AS PE_INAC_F,\n",
        "    COALESCE(PE_INAC_M, 0) AS PE_INAC_M,\n",
        "    COALESCE(POCUPADA, 0) AS POCUPADA,\n",
        "    COALESCE(POCUPADA_F, 0) AS POCUPADA_F,\n",
        "    COALESCE(POCUPADA_M, 0) AS POCUPADA_M,\n",
        "    COALESCE(PDESOCUP, 0) AS PDESOCUP,\n",
        "    COALESCE(PDESOCUP_F, 0) AS PDESOCUP_F,\n",
        "    COALESCE(PDESOCUP_M, 0) AS PDESOCUP_M,\n",
        "    COALESCE(PSINDER, 0) AS PSINDER,\n",
        "    COALESCE(PDER_SS, 0) AS PDER_SS,\n",
        "    COALESCE(PDER_IMSS, 0) AS PDER_IMSS,\n",
        "    COALESCE(PDER_ISTE, 0) AS PDER_ISTE,\n",
        "    COALESCE(PDER_ISTEE, 0) AS PDER_ISTEE,\n",
        "    COALESCE(PAFIL_PDOM, 0) AS PAFIL_PDOM,\n",
        "    COALESCE(PDER_SEGP, 0) AS PDER_SEGP,\n",
        "    COALESCE(PDER_IMSSB, 0) AS PDER_IMSSB,\n",
        "    COALESCE(PAFIL_IPRIV, 0) AS PAFIL_IPRIV,\n",
        "    COALESCE(PAFIL_OTRAI, 0) AS PAFIL_OTRAI,\n",
        "    COALESCE(P12YM_SOLT, 0) AS P12YM_SOLT,\n",
        "    COALESCE(P12YM_CASA, 0) AS P12YM_CASA,\n",
        "    COALESCE(P12YM_SEPA, 0) AS P12YM_SEPA,\n",
        "    COALESCE(PCATOLICA, 0) AS PCATOLICA,\n",
        "    COALESCE(PRO_CRIEVA, 0) AS PRO_CRIEVA,\n",
        "    COALESCE(POTRAS_REL, 0) AS POTRAS_REL,\n",
        "    COALESCE(PSIN_RELIG, 0) AS PSIN_RELIG,\n",
        "    COALESCE(TOTHOG, 0) AS TOTHOG,\n",
        "    COALESCE(HOGJEF_F, 0) AS HOGJEF_F,\n",
        "    COALESCE(HOGJEF_M, 0) AS HOGJEF_M,\n",
        "    COALESCE(POBHOG, 0) AS POBHOG,\n",
        "    COALESCE(PHOGJEF_F, 0) AS PHOGJEF_F,\n",
        "    COALESCE(PHOGJEF_M, 0) AS PHOGJEF_M,\n",
        "    COALESCE(VIVTOT, 0) AS VIVTOT,\n",
        "    COALESCE(TVIVHAB, 0) AS TVIVHAB,\n",
        "    COALESCE(TVIVPAR, 0) AS TVIVPAR,\n",
        "    COALESCE(VIVPAR_HAB, 0) AS VIVPAR_HAB,\n",
        "    COALESCE(VIVPARH_CV, 0) AS VIVPARH_CV,\n",
        "    COALESCE(TVIVPARHAB, 0) AS TVIVPARHAB,\n",
        "    COALESCE(VIVPAR_DES, 0) AS VIVPAR_DES,\n",
        "    COALESCE(VIVPAR_UT, 0) AS VIVPAR_UT,\n",
        "    COALESCE(OCUPVIVPAR, 0) AS OCUPVIVPAR,\n",
        "    COALESCE(PROM_OCUP, 0) AS PROM_OCUP,\n",
        "    COALESCE(PRO_OCUP_C, 0) AS PRO_OCUP_C,\n",
        "    COALESCE(VPH_PISODT, 0) AS VPH_PISODT,\n",
        "    COALESCE(VPH_PISOTI, 0) AS VPH_PISOTI,\n",
        "    COALESCE(VPH_1DOR, 0) AS VPH_1DOR,\n",
        "    COALESCE(VPH_2YMASD, 0) AS VPH_2YMASD,\n",
        "    COALESCE(VPH_1CUART, 0) AS VPH_1CUART,\n",
        "    COALESCE(VPH_2CUART, 0) AS VPH_2CUART,\n",
        "    COALESCE(VPH_3YMASC, 0) AS VPH_3YMASC,\n",
        "    COALESCE(VPH_C_ELEC, 0) AS VPH_C_ELEC,\n",
        "    COALESCE(VPH_S_ELEC, 0) AS VPH_S_ELEC,\n",
        "    COALESCE(VPH_AGUADV, 0) AS VPH_AGUADV,\n",
        "    COALESCE(VPH_AEASP, 0) AS VPH_AEASP,\n",
        "    COALESCE(VPH_AGUAFV, 0) AS VPH_AGUAFV,\n",
        "    COALESCE(VPH_TINACO, 0) AS VPH_TINACO,\n",
        "    COALESCE(VPH_CISTER, 0) AS VPH_CISTER,\n",
        "    COALESCE(VPH_EXCSA, 0) AS VPH_EXCSA,\n",
        "    COALESCE(VPH_LETR, 0) AS VPH_LETR,\n",
        "    COALESCE(VPH_DRENAJ, 0) AS VPH_DRENAJ,\n",
        "    COALESCE(VPH_NODREN, 0) AS VPH_NODREN,\n",
        "    COALESCE(VPH_C_SERV, 0) AS VPH_C_SERV,\n",
        "    COALESCE(VPH_NDEAED, 0) AS VPH_NDEAED,\n",
        "    COALESCE(VPH_DSADMA, 0) AS VPH_DSADMA,\n",
        "    COALESCE(VPH_NDACMM, 0) AS VPH_NDACMM,\n",
        "    COALESCE(VPH_SNBIEN, 0) AS VPH_SNBIEN,\n",
        "    COALESCE(VPH_REFRI, 0) AS VPH_REFRI,\n",
        "    COALESCE(VPH_LAVAD, 0) AS VPH_LAVAD,\n",
        "    COALESCE(VPH_HMICRO, 0) AS VPH_HMICRO,\n",
        "    COALESCE(VPH_AUTOM, 0) AS VPH_AUTOM,\n",
        "    COALESCE(VPH_MOTO, 0) AS VPH_MOTO,\n",
        "    COALESCE(VPH_BICI, 0) AS VPH_BICI,\n",
        "    COALESCE(VPH_RADIO, 0) AS VPH_RADIO,\n",
        "    COALESCE(VPH_TV, 0) AS VPH_TV,\n",
        "    COALESCE(VPH_PC, 0) AS VPH_PC,\n",
        "    COALESCE(VPH_TELEF, 0) AS VPH_TELEF,\n",
        "    COALESCE(VPH_CEL, 0) AS VPH_CEL,\n",
        "    COALESCE(VPH_INTER, 0) AS VPH_INTER,\n",
        "    COALESCE(VPH_STVP, 0) AS VPH_STVP,\n",
        "    COALESCE(VPH_SPMVPI, 0) AS VPH_SPMVPI,\n",
        "    COALESCE(VPH_CVJ, 0) AS VPH_CVJ,\n",
        "    COALESCE(VPH_SINRTV, 0) AS VPH_SINRTV,\n",
        "    COALESCE(VPH_SINLTC, 0) AS VPH_SINLTC,\n",
        "    COALESCE(VPH_SINCINT, 0) AS VPH_SINCINT,\n",
        "    COALESCE(VPH_SINTIC, 0) AS VPH_SINTIC,\n",
        "    ST_Centroid(geometry) AS geometry\n",
        "FROM src_db.censo_geo_int;\n",
        "\"\"\")\n",
        "print(\"Tabla 'censo_geo_int_centroid' creada.\")\n",
        "\n",
        "# --- Paso 2: Crear las tablas de buffers a partir de los centroides ---\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS censo_geo_int_centroid_buffer_100;\n",
        "CREATE TABLE censo_geo_int_centroid_buffer_100 AS\n",
        "SELECT *,\n",
        "       ST_Buffer(geometry, 0.000898) AS buffer_100\n",
        "FROM censo_geo_int_centroid;\n",
        "\"\"\")\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS censo_geo_int_centroid_buffer_500;\n",
        "CREATE TABLE censo_geo_int_centroid_buffer_500 AS\n",
        "SELECT *,\n",
        "       ST_Buffer(geometry, 0.00449) AS buffer_500\n",
        "FROM censo_geo_int_centroid;\n",
        "\"\"\")\n",
        "print(\"Tablas de buffers (100 m y 500 m) creadas a partir de los centroides.\")\n",
        "\n",
        "# --- Paso 3: Agregar (sumar) los campos numéricos de censo para cada punto de nacional_final_completa ---\n",
        "# Usamos ST_Intersects para relacionar la geometría de cada punto con el buffer de censo.\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS censo_agg_100;\n",
        "CREATE TABLE censo_agg_100 AS\n",
        "SELECT\n",
        "    n.id AS national_id,\n",
        "    SUM(c.POBTOT) AS sum_POBTOT,\n",
        "    SUM(c.POBFEM) AS sum_POBFEM,\n",
        "    SUM(c.POBMAS) AS sum_POBMAS,\n",
        "    SUM(c.P_0A2) AS sum_P_0A2,\n",
        "    SUM(c.P_0A2_F) AS sum_P_0A2_F,\n",
        "    SUM(c.P_0A2_M) AS sum_P_0A2_M,\n",
        "    SUM(c.P_3YMAS) AS sum_P_3YMAS,\n",
        "    SUM(c.P_3YMAS_F) AS sum_P_3YMAS_F,\n",
        "    SUM(c.P_3YMAS_M) AS sum_P_3YMAS_M,\n",
        "    SUM(c.P_5YMAS) AS sum_P_5YMAS,\n",
        "    SUM(c.P_5YMAS_F) AS sum_P_5YMAS_F,\n",
        "    SUM(c.P_5YMAS_M) AS sum_P_5YMAS_M,\n",
        "    SUM(c.P_12YMAS) AS sum_P_12YMAS,\n",
        "    SUM(c.P_12YMAS_F) AS sum_P_12YMAS_F,\n",
        "    SUM(c.P_12YMAS_M) AS sum_P_12YMAS_M,\n",
        "    SUM(c.P_15YMAS) AS sum_P_15YMAS,\n",
        "    SUM(c.P_15YMAS_F) AS sum_P_15YMAS_F,\n",
        "    SUM(c.P_15YMAS_M) AS sum_P_15YMAS_M,\n",
        "    SUM(c.P_18YMAS) AS sum_P_18YMAS,\n",
        "    SUM(c.P_18YMAS_F) AS sum_P_18YMAS_F,\n",
        "    SUM(c.P_18YMAS_M) AS sum_P_18YMAS_M,\n",
        "    SUM(c.P_3A5) AS sum_P_3A5,\n",
        "    SUM(c.P_3A5_F) AS sum_P_3A5_F,\n",
        "    SUM(c.P_3A5_M) AS sum_P_3A5_M,\n",
        "    SUM(c.P_6A11) AS sum_P_6A11,\n",
        "    SUM(c.P_6A11_F) AS sum_P_6A11_F,\n",
        "    SUM(c.P_6A11_M) AS sum_P_6A11_M,\n",
        "    SUM(c.P_8A14) AS sum_P_8A14,\n",
        "    SUM(c.P_8A14_F) AS sum_P_8A14_F,\n",
        "    SUM(c.P_8A14_M) AS sum_P_8A14_M,\n",
        "    SUM(c.P_12A14) AS sum_P_12A14,\n",
        "    SUM(c.P_12A14_F) AS sum_P_12A14_F,\n",
        "    SUM(c.P_12A14_M) AS sum_P_12A14_M,\n",
        "    SUM(c.P_15A17) AS sum_P_15A17,\n",
        "    SUM(c.P_15A17_F) AS sum_P_15A17_F,\n",
        "    SUM(c.P_15A17_M) AS sum_P_15A17_M,\n",
        "    SUM(c.P_18A24) AS sum_P_18A24,\n",
        "    SUM(c.P_18A24_F) AS sum_P_18A24_F,\n",
        "    SUM(c.P_18A24_M) AS sum_P_18A24_M,\n",
        "    SUM(c.P_15A49_F) AS sum_P_15A49_F,\n",
        "    SUM(c.P_60YMAS) AS sum_P_60YMAS,\n",
        "    SUM(c.P_60YMAS_F) AS sum_P_60YMAS_F,\n",
        "    SUM(c.P_60YMAS_M) AS sum_P_60YMAS_M,\n",
        "    SUM(c.REL_H_M) AS sum_REL_H_M,\n",
        "    SUM(c.POB0_14) AS sum_POB0_14,\n",
        "    SUM(c.POB15_64) AS sum_POB15_64,\n",
        "    SUM(c.POB65_MAS) AS sum_POB65_MAS,\n",
        "    SUM(c.PROM_HNV) AS sum_PROM_HNV,\n",
        "    SUM(c.PNACENT) AS sum_PNACENT,\n",
        "    SUM(c.PNACENT_F) AS sum_PNACENT_F,\n",
        "    SUM(c.PNACENT_M) AS sum_PNACENT_M,\n",
        "    SUM(c.PNACOE) AS sum_PNACOE,\n",
        "    SUM(c.PNACOE_F) AS sum_PNACOE_F,\n",
        "    SUM(c.PNACOE_M) AS sum_PNACOE_M,\n",
        "    SUM(c.PRES2015) AS sum_PRES2015,\n",
        "    SUM(c.PRES2015_F) AS sum_PRES2015_F,\n",
        "    SUM(c.PRES2015_M) AS sum_PRES2015_M,\n",
        "    SUM(c.PRESOE15) AS sum_PRESOE15,\n",
        "    SUM(c.PRESOE15_F) AS sum_PRESOE15_F,\n",
        "    SUM(c.PRESOE15_M) AS sum_PRESOE15_M,\n",
        "    SUM(c.P3YM_HLI) AS sum_P3YM_HLI,\n",
        "    SUM(c.P3YM_HLI_F) AS sum_P3YM_HLI_F,\n",
        "    SUM(c.P3YM_HLI_M) AS sum_P3YM_HLI_M,\n",
        "    SUM(c.P3HLINHE) AS sum_P3HLINHE,\n",
        "    SUM(c.P3HLINHE_F) AS sum_P3HLINHE_F,\n",
        "    SUM(c.P3HLINHE_M) AS sum_P3HLINHE_M,\n",
        "    SUM(c.P3HLI_HE) AS sum_P3HLI_HE,\n",
        "    SUM(c.P3HLI_HE_F) AS sum_P3HLI_HE_F,\n",
        "    SUM(c.P3HLI_HE_M) AS sum_P3HLI_HE_M,\n",
        "    SUM(c.P5_HLI) AS sum_P5_HLI,\n",
        "    SUM(c.P5_HLI_NHE) AS sum_P5_HLI_NHE,\n",
        "    SUM(c.P5_HLI_HE) AS sum_P5_HLI_HE,\n",
        "    SUM(c.PHOG_IND) AS sum_PHOG_IND,\n",
        "    SUM(c.POB_AFRO) AS sum_POB_AFRO,\n",
        "    SUM(c.POB_AFRO_F) AS sum_POB_AFRO_F,\n",
        "    SUM(c.POB_AFRO_M) AS sum_POB_AFRO_M,\n",
        "    SUM(c.PCON_DISC) AS sum_PCON_DISC,\n",
        "    SUM(c.PCDISC_MOT) AS sum_PCDISC_MOT,\n",
        "    SUM(c.PCDISC_VIS) AS sum_PCDISC_VIS,\n",
        "    SUM(c.PCDISC_LENG) AS sum_PCDISC_LENG,\n",
        "    SUM(c.PCDISC_AUD) AS sum_PCDISC_AUD,\n",
        "    SUM(c.PCDISC_MOT2) AS sum_PCDISC_MOT2,\n",
        "    SUM(c.PCDISC_MEN) AS sum_PCDISC_MEN,\n",
        "    SUM(c.PCON_LIMI) AS sum_PCON_LIMI,\n",
        "    SUM(c.PCLIM_CSB) AS sum_PCLIM_CSB,\n",
        "    SUM(c.PCLIM_VIS) AS sum_PCLIM_VIS,\n",
        "    SUM(c.PCLIM_HACO) AS sum_PCLIM_HACO,\n",
        "    SUM(c.PCLIM_OAUD) AS sum_PCLIM_OAUD,\n",
        "    SUM(c.PCLIM_MOT2) AS sum_PCLIM_MOT2,\n",
        "    SUM(c.PCLIM_RE_CO) AS sum_PCLIM_RE_CO,\n",
        "    SUM(c.PCLIM_PMEN) AS sum_PCLIM_PMEN,\n",
        "    SUM(c.PSIND_LIM) AS sum_PSIND_LIM,\n",
        "    SUM(c.P3A5_NOA) AS sum_P3A5_NOA,\n",
        "    SUM(c.P3A5_NOA_F) AS sum_P3A5_NOA_F,\n",
        "    SUM(c.P3A5_NOA_M) AS sum_P3A5_NOA_M,\n",
        "    SUM(c.P6A11_NOA) AS sum_P6A11_NOA,\n",
        "    SUM(c.P6A11_NOAF) AS sum_P6A11_NOAF,\n",
        "    SUM(c.P6A11_NOAM) AS sum_P6A11_NOAM,\n",
        "    SUM(c.P12A14NOA) AS sum_P12A14NOA,\n",
        "    SUM(c.P12A14NOAF) AS sum_P12A14NOAF,\n",
        "    SUM(c.P12A14NOAM) AS sum_P12A14NOAM,\n",
        "    SUM(c.P15A17A) AS sum_P15A17A,\n",
        "    SUM(c.P15A17A_F) AS sum_P15A17A_F,\n",
        "    SUM(c.P15A17A_M) AS sum_P15A17A_M,\n",
        "    SUM(c.P18A24A) AS sum_P18A24A,\n",
        "    SUM(c.P18A24A_F) AS sum_P18A24A_F,\n",
        "    SUM(c.P18A24A_M) AS sum_P18A24A_M,\n",
        "    SUM(c.P8A14AN) AS sum_P8A14AN,\n",
        "    SUM(c.P8A14AN_F) AS sum_P8A14AN_F,\n",
        "    SUM(c.P8A14AN_M) AS sum_P8A14AN_M,\n",
        "    SUM(c.P15YM_AN) AS sum_P15YM_AN,\n",
        "    SUM(c.P15YM_AN_F) AS sum_P15YM_AN_F,\n",
        "    SUM(c.P15YM_AN_M) AS sum_P15YM_AN_M,\n",
        "    SUM(c.P15YM_SE) AS sum_P15YM_SE,\n",
        "    SUM(c.P15YM_SE_F) AS sum_P15YM_SE_F,\n",
        "    SUM(c.P15YM_SE_M) AS sum_P15YM_SE_M,\n",
        "    SUM(c.P15PRI_IN) AS sum_P15PRI_IN,\n",
        "    SUM(c.P15PRI_INF) AS sum_P15PRI_INF,\n",
        "    SUM(c.P15PRI_INM) AS sum_P15PRI_INM,\n",
        "    SUM(c.P15PRI_CO) AS sum_P15PRI_CO,\n",
        "    SUM(c.P15PRI_COF) AS sum_P15PRI_COF,\n",
        "    SUM(c.P15PRI_COM) AS sum_P15PRI_COM,\n",
        "    SUM(c.P15SEC_IN) AS sum_P15SEC_IN,\n",
        "    SUM(c.P15SEC_INF) AS sum_P15SEC_INF,\n",
        "    SUM(c.P15SEC_INM) AS sum_P15SEC_INM,\n",
        "    SUM(c.P15SEC_CO) AS sum_P15SEC_CO,\n",
        "    SUM(c.P15SEC_COF) AS sum_P15SEC_COF,\n",
        "    SUM(c.P15SEC_COM) AS sum_P15SEC_COM,\n",
        "    SUM(c.P18YM_PB) AS sum_P18YM_PB,\n",
        "    SUM(c.P18YM_PB_F) AS sum_P18YM_PB_F,\n",
        "    SUM(c.P18YM_PB_M) AS sum_P18YM_PB_M,\n",
        "    SUM(c.GRAPROES) AS sum_GRAPROES,\n",
        "    SUM(c.GRAPROES_F) AS sum_GRAPROES_F,\n",
        "    SUM(c.GRAPROES_M) AS sum_GRAPROES_M,\n",
        "    SUM(c.PEA) AS sum_PEA,\n",
        "    SUM(c.PEA_F) AS sum_PEA_F,\n",
        "    SUM(c.PEA_M) AS sum_PEA_M,\n",
        "    SUM(c.PE_INAC) AS sum_PE_INAC,\n",
        "    SUM(c.PE_INAC_F) AS sum_PE_INAC_F,\n",
        "    SUM(c.PE_INAC_M) AS sum_PE_INAC_M,\n",
        "    SUM(c.POCUPADA) AS sum_POCUPADA,\n",
        "    SUM(c.POCUPADA_F) AS sum_POCUPADA_F,\n",
        "    SUM(c.POCUPADA_M) AS sum_POCUPADA_M,\n",
        "    SUM(c.PDESOCUP) AS sum_PDESOCUP,\n",
        "    SUM(c.PDESOCUP_F) AS sum_PDESOCUP_F,\n",
        "    SUM(c.PDESOCUP_M) AS sum_PDESOCUP_M,\n",
        "    SUM(c.PSINDER) AS sum_PSINDER,\n",
        "    SUM(c.PDER_SS) AS sum_PDER_SS,\n",
        "    SUM(c.PDER_IMSS) AS sum_PDER_IMSS,\n",
        "    SUM(c.PDER_ISTE) AS sum_PDER_ISTE,\n",
        "    SUM(c.PDER_ISTEE) AS sum_PDER_ISTEE,\n",
        "    SUM(c.PAFIL_PDOM) AS sum_PAFIL_PDOM,\n",
        "    SUM(c.PDER_SEGP) AS sum_PDER_SEGP,\n",
        "    SUM(c.PDER_IMSSB) AS sum_PDER_IMSSB,\n",
        "    SUM(c.PAFIL_IPRIV) AS sum_PAFIL_IPRIV,\n",
        "    SUM(c.PAFIL_OTRAI) AS sum_PAFIL_OTRAI,\n",
        "    SUM(c.P12YM_SOLT) AS sum_P12YM_SOLT,\n",
        "    SUM(c.P12YM_CASA) AS sum_P12YM_CASA,\n",
        "    SUM(c.P12YM_SEPA) AS sum_P12YM_SEPA,\n",
        "    SUM(c.PCATOLICA) AS sum_PCATOLICA,\n",
        "    SUM(c.PRO_CRIEVA) AS sum_PRO_CRIEVA,\n",
        "    SUM(c.POTRAS_REL) AS sum_POTRAS_REL,\n",
        "    SUM(c.PSIN_RELIG) AS sum_PSIN_RELIG,\n",
        "    SUM(c.TOTHOG) AS sum_TOTHOG,\n",
        "    SUM(c.HOGJEF_F) AS sum_HOGJEF_F,\n",
        "    SUM(c.HOGJEF_M) AS sum_HOGJEF_M,\n",
        "    SUM(c.POBHOG) AS sum_POBHOG,\n",
        "    SUM(c.PHOGJEF_F) AS sum_PHOGJEF_F,\n",
        "    SUM(c.PHOGJEF_M) AS sum_PHOGJEF_M,\n",
        "    SUM(c.VIVTOT) AS sum_VIVTOT,\n",
        "    SUM(c.TVIVHAB) AS sum_TVIVHAB,\n",
        "    SUM(c.TVIVPAR) AS sum_TVIVPAR,\n",
        "    SUM(c.VIVPAR_HAB) AS sum_VIVPAR_HAB,\n",
        "    SUM(c.VIVPARH_CV) AS sum_VIVPARH_CV,\n",
        "    SUM(c.TVIVPARHAB) AS sum_TVIVPARHAB,\n",
        "    SUM(c.VIVPAR_DES) AS sum_VIVPAR_DES,\n",
        "    SUM(c.VIVPAR_UT) AS sum_VIVPAR_UT,\n",
        "    SUM(c.OCUPVIVPAR) AS sum_OCUPVIVPAR,\n",
        "    SUM(c.PROM_OCUP) AS sum_PROM_OCUP,\n",
        "    SUM(c.PRO_OCUP_C) AS sum_PRO_OCUP_C,\n",
        "    SUM(c.VPH_PISODT) AS sum_VPH_PISODT,\n",
        "    SUM(c.VPH_PISOTI) AS sum_VPH_PISOTI,\n",
        "    SUM(c.VPH_1DOR) AS sum_VPH_1DOR,\n",
        "    SUM(c.VPH_2YMASD) AS sum_VPH_2YMASD,\n",
        "    SUM(c.VPH_1CUART) AS sum_VPH_1CUART,\n",
        "    SUM(c.VPH_2CUART) AS sum_VPH_2CUART,\n",
        "    SUM(c.VPH_3YMASC) AS sum_VPH_3YMASC,\n",
        "    SUM(c.VPH_C_ELEC) AS sum_VPH_C_ELEC,\n",
        "    SUM(c.VPH_S_ELEC) AS sum_VPH_S_ELEC,\n",
        "    SUM(c.VPH_AGUADV) AS sum_VPH_AGUADV,\n",
        "    SUM(c.VPH_AEASP) AS sum_VPH_AEASP,\n",
        "    SUM(c.VPH_AGUAFV) AS sum_VPH_AGUAFV,\n",
        "    SUM(c.VPH_TINACO) AS sum_VPH_TINACO,\n",
        "    SUM(c.VPH_CISTER) AS sum_VPH_CISTER,\n",
        "    SUM(c.VPH_EXCSA) AS sum_VPH_EXCSA,\n",
        "    SUM(c.VPH_LETR) AS sum_VPH_LETR,\n",
        "    SUM(c.VPH_DRENAJ) AS sum_VPH_DRENAJ,\n",
        "    SUM(c.VPH_NODREN) AS sum_VPH_NODREN,\n",
        "    SUM(c.VPH_C_SERV) AS sum_VPH_C_SERV,\n",
        "    SUM(c.VPH_NDEAED) AS sum_VPH_NDEAED,\n",
        "    SUM(c.VPH_DSADMA) AS sum_VPH_DSADMA,\n",
        "    SUM(c.VPH_NDACMM) AS sum_VPH_NDACMM,\n",
        "    SUM(c.VPH_SNBIEN) AS sum_VPH_SNBIEN,\n",
        "    SUM(c.VPH_REFRI) AS sum_VPH_REFRI,\n",
        "    SUM(c.VPH_LAVAD) AS sum_VPH_LAVAD,\n",
        "    SUM(c.VPH_HMICRO) AS sum_VPH_HMICRO,\n",
        "    SUM(c.VPH_AUTOM) AS sum_VPH_AUTOM,\n",
        "    SUM(c.VPH_MOTO) AS sum_VPH_MOTO,\n",
        "    SUM(c.VPH_BICI) AS sum_VPH_BICI,\n",
        "    SUM(c.VPH_RADIO) AS sum_VPH_RADIO,\n",
        "    SUM(c.VPH_TV) AS sum_VPH_TV,\n",
        "    SUM(c.VPH_PC) AS sum_VPH_PC,\n",
        "    SUM(c.VPH_TELEF) AS sum_VPH_TELEF,\n",
        "    SUM(c.VPH_CEL) AS sum_VPH_CEL,\n",
        "    SUM(c.VPH_INTER) AS sum_VPH_INTER,\n",
        "    SUM(c.VPH_STVP) AS sum_VPH_STVP,\n",
        "    SUM(c.VPH_SPMVPI) AS sum_VPH_SPMVPI,\n",
        "    SUM(c.VPH_CVJ) AS sum_VPH_CVJ,\n",
        "    SUM(c.VPH_SINRTV) AS sum_VPH_SINRTV,\n",
        "    SUM(c.VPH_SINLTC) AS sum_VPH_SINLTC,\n",
        "    SUM(c.VPH_SINCINT) AS sum_VPH_SINCINT,\n",
        "    SUM(c.VPH_SINTIC) AS sum_VPH_SINTIC\n",
        "FROM nacional_final_completa n\n",
        "JOIN censo_geo_int_centroid_buffer_100 c\n",
        "  ON ST_Intersects(n.geometry, c.buffer_100)\n",
        "GROUP BY n.id;\n",
        "\"\"\")\n",
        "\n",
        "conn.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS censo_agg_500;\n",
        "CREATE TABLE censo_agg_500 AS\n",
        "SELECT\n",
        "    n.id AS national_id,\n",
        "    SUM(c.POBTOT) AS sum_POBTOT,\n",
        "    SUM(c.POBFEM) AS sum_POBFEM,\n",
        "    SUM(c.POBMAS) AS sum_POBMAS,\n",
        "    SUM(c.P_0A2) AS sum_P_0A2,\n",
        "    SUM(c.P_0A2_F) AS sum_P_0A2_F,\n",
        "    SUM(c.P_0A2_M) AS sum_P_0A2_M,\n",
        "    SUM(c.P_3YMAS) AS sum_P_3YMAS,\n",
        "    SUM(c.P_3YMAS_F) AS sum_P_3YMAS_F,\n",
        "    SUM(c.P_3YMAS_M) AS sum_P_3YMAS_M,\n",
        "    SUM(c.P_5YMAS) AS sum_P_5YMAS,\n",
        "    SUM(c.P_5YMAS_F) AS sum_P_5YMAS_F,\n",
        "    SUM(c.P_5YMAS_M) AS sum_P_5YMAS_M,\n",
        "    SUM(c.P_12YMAS) AS sum_P_12YMAS,\n",
        "    SUM(c.P_12YMAS_F) AS sum_P_12YMAS_F,\n",
        "    SUM(c.P_12YMAS_M) AS sum_P_12YMAS_M,\n",
        "    SUM(c.P_15YMAS) AS sum_P_15YMAS,\n",
        "    SUM(c.P_15YMAS_F) AS sum_P_15YMAS_F,\n",
        "    SUM(c.P_15YMAS_M) AS sum_P_15YMAS_M,\n",
        "    SUM(c.P_18YMAS) AS sum_P_18YMAS,\n",
        "    SUM(c.P_18YMAS_F) AS sum_P_18YMAS_F,\n",
        "    SUM(c.P_18YMAS_M) AS sum_P_18YMAS_M,\n",
        "    SUM(c.P_3A5) AS sum_P_3A5,\n",
        "    SUM(c.P_3A5_F) AS sum_P_3A5_F,\n",
        "    SUM(c.P_3A5_M) AS sum_P_3A5_M,\n",
        "    SUM(c.P_6A11) AS sum_P_6A11,\n",
        "    SUM(c.P_6A11_F) AS sum_P_6A11_F,\n",
        "    SUM(c.P_6A11_M) AS sum_P_6A11_M,\n",
        "    SUM(c.P_8A14) AS sum_P_8A14,\n",
        "    SUM(c.P_8A14_F) AS sum_P_8A14_F,\n",
        "    SUM(c.P_8A14_M) AS sum_P_8A14_M,\n",
        "    SUM(c.P_12A14) AS sum_P_12A14,\n",
        "    SUM(c.P_12A14_F) AS sum_P_12A14_F,\n",
        "    SUM(c.P_12A14_M) AS sum_P_12A14_M,\n",
        "    SUM(c.P_15A17) AS sum_P_15A17,\n",
        "    SUM(c.P_15A17_F) AS sum_P_15A17_F,\n",
        "    SUM(c.P_15A17_M) AS sum_P_15A17_M,\n",
        "    SUM(c.P_18A24) AS sum_P_18A24,\n",
        "    SUM(c.P_18A24_F) AS sum_P_18A24_F,\n",
        "    SUM(c.P_18A24_M) AS sum_P_18A24_M,\n",
        "    SUM(c.P_15A49_F) AS sum_P_15A49_F,\n",
        "    SUM(c.P_60YMAS) AS sum_P_60YMAS,\n",
        "    SUM(c.P_60YMAS_F) AS sum_P_60YMAS_F,\n",
        "    SUM(c.P_60YMAS_M) AS sum_P_60YMAS_M,\n",
        "    SUM(c.REL_H_M) AS sum_REL_H_M,\n",
        "    SUM(c.POB0_14) AS sum_POB0_14,\n",
        "    SUM(c.POB15_64) AS sum_POB15_64,\n",
        "    SUM(c.POB65_MAS) AS sum_POB65_MAS,\n",
        "    SUM(c.PROM_HNV) AS sum_PROM_HNV,\n",
        "    SUM(c.PNACENT) AS sum_PNACENT,\n",
        "    SUM(c.PNACENT_F) AS sum_PNACENT_F,\n",
        "    SUM(c.PNACENT_M) AS sum_PNACENT_M,\n",
        "    SUM(c.PNACOE) AS sum_PNACOE,\n",
        "    SUM(c.PNACOE_F) AS sum_PNACOE_F,\n",
        "    SUM(c.PNACOE_M) AS sum_PNACOE_M,\n",
        "    SUM(c.PRES2015) AS sum_PRES2015,\n",
        "    SUM(c.PRES2015_F) AS sum_PRES2015_F,\n",
        "    SUM(c.PRES2015_M) AS sum_PRES2015_M,\n",
        "    SUM(c.PRESOE15) AS sum_PRESOE15,\n",
        "    SUM(c.PRESOE15_F) AS sum_PRESOE15_F,\n",
        "    SUM(c.PRESOE15_M) AS sum_PRESOE15_M,\n",
        "    SUM(c.P3YM_HLI) AS sum_P3YM_HLI,\n",
        "    SUM(c.P3YM_HLI_F) AS sum_P3YM_HLI_F,\n",
        "    SUM(c.P3YM_HLI_M) AS sum_P3YM_HLI_M,\n",
        "    SUM(c.P3HLINHE) AS sum_P3HLINHE,\n",
        "    SUM(c.P3HLINHE_F) AS sum_P3HLINHE_F,\n",
        "    SUM(c.P3HLINHE_M) AS sum_P3HLINHE_M,\n",
        "    SUM(c.P3HLI_HE) AS sum_P3HLI_HE,\n",
        "    SUM(c.P3HLI_HE_F) AS sum_P3HLI_HE_F,\n",
        "    SUM(c.P3HLI_HE_M) AS sum_P3HLI_HE_M,\n",
        "    SUM(c.P5_HLI) AS sum_P5_HLI,\n",
        "    SUM(c.P5_HLI_NHE) AS sum_P5_HLI_NHE,\n",
        "    SUM(c.P5_HLI_HE) AS sum_P5_HLI_HE,\n",
        "    SUM(c.PHOG_IND) AS sum_PHOG_IND,\n",
        "    SUM(c.POB_AFRO) AS sum_POB_AFRO,\n",
        "    SUM(c.POB_AFRO_F) AS sum_POB_AFRO_F,\n",
        "    SUM(c.POB_AFRO_M) AS sum_POB_AFRO_M,\n",
        "    SUM(c.PCON_DISC) AS sum_PCON_DISC,\n",
        "    SUM(c.PCDISC_MOT) AS sum_PCDISC_MOT,\n",
        "    SUM(c.PCDISC_VIS) AS sum_PCDISC_VIS,\n",
        "    SUM(c.PCDISC_LENG) AS sum_PCDISC_LENG,\n",
        "    SUM(c.PCDISC_AUD) AS sum_PCDISC_AUD,\n",
        "    SUM(c.PCDISC_MOT2) AS sum_PCDISC_MOT2,\n",
        "    SUM(c.PCDISC_MEN) AS sum_PCDISC_MEN,\n",
        "    SUM(c.PCON_LIMI) AS sum_PCON_LIMI,\n",
        "    SUM(c.PCLIM_CSB) AS sum_PCLIM_CSB,\n",
        "    SUM(c.PCLIM_VIS) AS sum_PCLIM_VIS,\n",
        "    SUM(c.PCLIM_HACO) AS sum_PCLIM_HACO,\n",
        "    SUM(c.PCLIM_OAUD) AS sum_PCLIM_OAUD,\n",
        "    SUM(c.PCLIM_MOT2) AS sum_PCLIM_MOT2,\n",
        "    SUM(c.PCLIM_RE_CO) AS sum_PCLIM_RE_CO,\n",
        "    SUM(c.PCLIM_PMEN) AS sum_PCLIM_PMEN,\n",
        "    SUM(c.PSIND_LIM) AS sum_PSIND_LIM,\n",
        "    SUM(c.P3A5_NOA) AS sum_P3A5_NOA,\n",
        "    SUM(c.P3A5_NOA_F) AS sum_P3A5_NOA_F,\n",
        "    SUM(c.P3A5_NOA_M) AS sum_P3A5_NOA_M,\n",
        "    SUM(c.P6A11_NOA) AS sum_P6A11_NOA,\n",
        "    SUM(c.P6A11_NOAF) AS sum_P6A11_NOAF,\n",
        "    SUM(c.P6A11_NOAM) AS sum_P6A11_NOAM,\n",
        "    SUM(c.P12A14NOA) AS sum_P12A14NOA,\n",
        "    SUM(c.P12A14NOAF) AS sum_P12A14NOAF,\n",
        "    SUM(c.P12A14NOAM) AS sum_P12A14NOAM,\n",
        "    SUM(c.P15A17A) AS sum_P15A17A,\n",
        "    SUM(c.P15A17A_F) AS sum_P15A17A_F,\n",
        "    SUM(c.P15A17A_M) AS sum_P15A17A_M,\n",
        "    SUM(c.P18A24A) AS sum_P18A24A,\n",
        "    SUM(c.P18A24A_F) AS sum_P18A24A_F,\n",
        "    SUM(c.P18A24A_M) AS sum_P18A24A_M,\n",
        "    SUM(c.P8A14AN) AS sum_P8A14AN,\n",
        "    SUM(c.P8A14AN_F) AS sum_P8A14AN_F,\n",
        "    SUM(c.P8A14AN_M) AS sum_P8A14AN_M,\n",
        "    SUM(c.P15YM_AN) AS sum_P15YM_AN,\n",
        "    SUM(c.P15YM_AN_F) AS sum_P15YM_AN_F,\n",
        "    SUM(c.P15YM_AN_M) AS sum_P15YM_AN_M,\n",
        "    SUM(c.P15YM_SE) AS sum_P15YM_SE,\n",
        "    SUM(c.P15YM_SE_F) AS sum_P15YM_SE_F,\n",
        "    SUM(c.P15YM_SE_M) AS sum_P15YM_SE_M,\n",
        "    SUM(c.P15PRI_IN) AS sum_P15PRI_IN,\n",
        "    SUM(c.P15PRI_INF) AS sum_P15PRI_INF,\n",
        "    SUM(c.P15PRI_INM) AS sum_P15PRI_INM,\n",
        "    SUM(c.P15PRI_CO) AS sum_P15PRI_CO,\n",
        "    SUM(c.P15PRI_COF) AS sum_P15PRI_COF,\n",
        "    SUM(c.P15PRI_COM) AS sum_P15PRI_COM,\n",
        "    SUM(c.P15SEC_IN) AS sum_P15SEC_IN,\n",
        "    SUM(c.P15SEC_INF) AS sum_P15SEC_INF,\n",
        "    SUM(c.P15SEC_INM) AS sum_P15SEC_INM,\n",
        "    SUM(c.P15SEC_CO) AS sum_P15SEC_CO,\n",
        "    SUM(c.P15SEC_COF) AS sum_P15SEC_COF,\n",
        "    SUM(c.P15SEC_COM) AS sum_P15SEC_COM,\n",
        "    SUM(c.P18YM_PB) AS sum_P18YM_PB,\n",
        "    SUM(c.P18YM_PB_F) AS sum_P18YM_PB_F,\n",
        "    SUM(c.P18YM_PB_M) AS sum_P18YM_PB_M,\n",
        "    SUM(c.GRAPROES) AS sum_GRAPROES,\n",
        "    SUM(c.GRAPROES_F) AS sum_GRAPROES_F,\n",
        "    SUM(c.GRAPROES_M) AS sum_GRAPROES_M,\n",
        "    SUM(c.PEA) AS sum_PEA,\n",
        "    SUM(c.PEA_F) AS sum_PEA_F,\n",
        "    SUM(c.PEA_M) AS sum_PEA_M,\n",
        "    SUM(c.PE_INAC) AS sum_PE_INAC,\n",
        "    SUM(c.PE_INAC_F) AS sum_PE_INAC_F,\n",
        "    SUM(c.PE_INAC_M) AS sum_PE_INAC_M,\n",
        "    SUM(c.POCUPADA) AS sum_POCUPADA,\n",
        "    SUM(c.POCUPADA_F) AS sum_POCUPADA_F,\n",
        "    SUM(c.POCUPADA_M) AS sum_POCUPADA_M,\n",
        "    SUM(c.PDESOCUP) AS sum_PDESOCUP,\n",
        "    SUM(c.PDESOCUP_F) AS sum_PDESOCUP_F,\n",
        "    SUM(c.PDESOCUP_M) AS sum_PDESOCUP_M,\n",
        "    SUM(c.PSINDER) AS sum_PSINDER,\n",
        "    SUM(c.PDER_SS) AS sum_PDER_SS,\n",
        "    SUM(c.PDER_IMSS) AS sum_PDER_IMSS,\n",
        "    SUM(c.PDER_ISTE) AS sum_PDER_ISTE,\n",
        "    SUM(c.PDER_ISTEE) AS sum_PDER_ISTEE,\n",
        "    SUM(c.PAFIL_PDOM) AS sum_PAFIL_PDOM,\n",
        "    SUM(c.PDER_SEGP) AS sum_PDER_SEGP,\n",
        "    SUM(c.PDER_IMSSB) AS sum_PDER_IMSSB,\n",
        "    SUM(c.PAFIL_IPRIV) AS sum_PAFIL_IPRIV,\n",
        "    SUM(c.PAFIL_OTRAI) AS sum_PAFIL_OTRAI,\n",
        "    SUM(c.P12YM_SOLT) AS sum_P12YM_SOLT,\n",
        "    SUM(c.P12YM_CASA) AS sum_P12YM_CASA,\n",
        "    SUM(c.P12YM_SEPA) AS sum_P12YM_SEPA,\n",
        "    SUM(c.PCATOLICA) AS sum_PCATOLICA,\n",
        "    SUM(c.PRO_CRIEVA) AS sum_PRO_CRIEVA,\n",
        "    SUM(c.POTRAS_REL) AS sum_POTRAS_REL,\n",
        "    SUM(c.PSIN_RELIG) AS sum_PSIN_RELIG,\n",
        "    SUM(c.TOTHOG) AS sum_TOTHOG,\n",
        "    SUM(c.HOGJEF_F) AS sum_HOGJEF_F,\n",
        "    SUM(c.HOGJEF_M) AS sum_HOGJEF_M,\n",
        "    SUM(c.POBHOG) AS sum_POBHOG,\n",
        "    SUM(c.PHOGJEF_F) AS sum_PHOGJEF_F,\n",
        "    SUM(c.PHOGJEF_M) AS sum_PHOGJEF_M,\n",
        "    SUM(c.VIVTOT) AS sum_VIVTOT,\n",
        "    SUM(c.TVIVHAB) AS sum_TVIVHAB,\n",
        "    SUM(c.TVIVPAR) AS sum_TVIVPAR,\n",
        "    SUM(c.VIVPAR_HAB) AS sum_VIVPAR_HAB,\n",
        "    SUM(c.VIVPARH_CV) AS sum_VIVPARH_CV,\n",
        "    SUM(c.TVIVPARHAB) AS sum_TVIVPARHAB,\n",
        "    SUM(c.VIVPAR_DES) AS sum_VIVPAR_DES,\n",
        "    SUM(c.VIVPAR_UT) AS sum_VIVPAR_UT,\n",
        "    SUM(c.OCUPVIVPAR) AS sum_OCUPVIVPAR,\n",
        "    SUM(c.PROM_OCUP) AS sum_PROM_OCUP,\n",
        "    SUM(c.PRO_OCUP_C) AS sum_PRO_OCUP_C,\n",
        "    SUM(c.VPH_PISODT) AS sum_VPH_PISODT,\n",
        "    SUM(c.VPH_PISOTI) AS sum_VPH_PISOTI,\n",
        "    SUM(c.VPH_1DOR) AS sum_VPH_1DOR,\n",
        "    SUM(c.VPH_2YMASD) AS sum_VPH_2YMASD,\n",
        "    SUM(c.VPH_1CUART) AS sum_VPH_1CUART,\n",
        "    SUM(c.VPH_2CUART) AS sum_VPH_2CUART,\n",
        "    SUM(c.VPH_3YMASC) AS sum_VPH_3YMASC,\n",
        "    SUM(c.VPH_C_ELEC) AS sum_VPH_C_ELEC,\n",
        "    SUM(c.VPH_S_ELEC) AS sum_VPH_S_ELEC,\n",
        "    SUM(c.VPH_AGUADV) AS sum_VPH_AGUADV,\n",
        "    SUM(c.VPH_AEASP) AS sum_VPH_AEASP,\n",
        "    SUM(c.VPH_AGUAFV) AS sum_VPH_AGUAFV,\n",
        "    SUM(c.VPH_TINACO) AS sum_VPH_TINACO,\n",
        "    SUM(c.VPH_CISTER) AS sum_VPH_CISTER,\n",
        "    SUM(c.VPH_EXCSA) AS sum_VPH_EXCSA,\n",
        "    SUM(c.VPH_LETR) AS sum_VPH_LETR,\n",
        "    SUM(c.VPH_DRENAJ) AS sum_VPH_DRENAJ,\n",
        "    SUM(c.VPH_NODREN) AS sum_VPH_NODREN,\n",
        "    SUM(c.VPH_C_SERV) AS sum_VPH_C_SERV,\n",
        "    SUM(c.VPH_NDEAED) AS sum_VPH_NDEAED,\n",
        "    SUM(c.VPH_DSADMA) AS sum_VPH_DSADMA,\n",
        "    SUM(c.VPH_NDACMM) AS sum_VPH_NDACMM,\n",
        "    SUM(c.VPH_SNBIEN) AS sum_VPH_SNBIEN,\n",
        "    SUM(c.VPH_REFRI) AS sum_VPH_REFRI,\n",
        "    SUM(c.VPH_LAVAD) AS sum_VPH_LAVAD,\n",
        "    SUM(c.VPH_HMICRO) AS sum_VPH_HMICRO,\n",
        "    SUM(c.VPH_AUTOM) AS sum_VPH_AUTOM,\n",
        "    SUM(c.VPH_MOTO) AS sum_VPH_MOTO,\n",
        "    SUM(c.VPH_BICI) AS sum_VPH_BICI,\n",
        "    SUM(c.VPH_RADIO) AS sum_VPH_RADIO,\n",
        "    SUM(c.VPH_TV) AS sum_VPH_TV,\n",
        "    SUM(c.VPH_PC) AS sum_VPH_PC,\n",
        "    SUM(c.VPH_TELEF) AS sum_VPH_TELEF,\n",
        "    SUM(c.VPH_CEL) AS sum_VPH_CEL,\n",
        "    SUM(c.VPH_INTER) AS sum_VPH_INTER,\n",
        "    SUM(c.VPH_STVP) AS sum_VPH_STVP,\n",
        "    SUM(c.VPH_SPMVPI) AS sum_VPH_SPMVPI,\n",
        "    SUM(c.VPH_CVJ) AS sum_VPH_CVJ,\n",
        "    SUM(c.VPH_SINRTV) AS sum_VPH_SINRTV,\n",
        "    SUM(c.VPH_SINLTC) AS sum_VPH_SINLTC,\n",
        "    SUM(c.VPH_SINCINT) AS sum_VPH_SINCINT,\n",
        "    SUM(c.VPH_SINTIC) AS sum_VPH_SINTIC\n",
        "FROM nacional_final_completa n\n",
        "JOIN censo_geo_int_centroid_buffer_500 c\n",
        "  ON ST_Intersects(n.geometry, c.buffer_500)\n",
        "GROUP BY n.id;\n",
        "\"\"\")\n",
        "print(\"Agregaciones de censo para buffers de 100 m y 500 m creadas.\")\n",
        "\n",
        "# --- Paso 4: Unir las agregaciones de censo con la tabla nacional_final_completa ---\n",
        "# Obtener la lista de columnas de la tabla censo_agg_100 (se espera que sean las mismas en censo_agg_500)\n",
        "schema = conn.execute(\"PRAGMA table_info(censo_agg_100)\").fetchall()\n",
        "# Cada fila del schema tiene la forma: (cid, name, type, notnull, dflt_value, pk)\n",
        "cols = [row[1] for row in schema if row[1].startswith(\"sum_\")]\n",
        "\n",
        "# Generar la lista de expresiones para censo_agg_100 (buffer 100)\n",
        "col_list_100 = \",\\n    \".join([f\"COALESCE(a.{col}, 0) AS censo_{col[4:]}_100\" for col in cols])\n",
        "# Generar la lista de expresiones para censo_agg_500 (buffer 500)\n",
        "col_list_500 = \",\\n    \".join([f\"COALESCE(b.{col}, 0) AS censo_{col[4:]}_500\" for col in cols])\n",
        "\n",
        "# Construir el query final usando f-string\n",
        "query = f\"\"\"\n",
        "DROP TABLE IF EXISTS nacional_final_completa_con_censo;\n",
        "CREATE TABLE nacional_final_completa_con_censo AS\n",
        "SELECT\n",
        "    n.*,\n",
        "    {col_list_100},\n",
        "    {col_list_500}\n",
        "FROM nacional_final_completa n\n",
        "LEFT JOIN censo_agg_100 a ON n.id = a.national_id\n",
        "LEFT JOIN censo_agg_500 b ON n.id = b.national_id;\n",
        "\"\"\"\n",
        "\n",
        "# Ejecutar el query\n",
        "conn.execute(query)\n",
        "\n",
        "print(\"Tabla 'nacional_final_completa_con_censo' creada con las variables agregadas del censo.\")\n",
        "\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVHYPsVsLn17"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos\n",
        "db_path = \"/content/denue_total_est_per_ocu_final_5.duckdb\"\n",
        "conn = duckdb.connect(db_path)\n",
        "\n",
        "# Ejecutar PRAGMA table_info para obtener la estructura de la tabla\n",
        "fields = conn.execute(\"PRAGMA table_info(nacional_final_completa_con_censo)\").fetchall()\n",
        "\n",
        "print(\"Lista de campos de 'nacional_final_completa_con_censo':\")\n",
        "for field in fields:\n",
        "    # Cada 'field' es una tupla: (cid, name, type, notnull, dflt_value, pk)\n",
        "    print(f\"- {field[1]} ({field[2]})\")\n",
        "\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9keT5s_Ln4t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2WlsGZmLn7f"
      },
      "outputs": [],
      "source": [
        "# Conectar a la base de datos y extraer los datos con la geometría en WKB\n",
        "conn = duckdb.connect('/content/denue_total_est_per_ocu_final_5.duckdb')\n",
        "conn.execute(\"INSTALL spatial; LOAD spatial;\")\n",
        "\n",
        "df = conn.execute(\"\"\"\n",
        "    SELECT\n",
        "        *,\n",
        "        ST_AsWKB(geometry) AS geom_wkb\n",
        "    FROM nacional_final_completa_con_censo\n",
        "\"\"\").df()\n",
        "conn.close()\n",
        "\n",
        "# Función segura para cargar la geometría a partir de WKB\n",
        "def safe_wkb_load(x):\n",
        "    # Verificar si x es del tipo adecuado (bytes o bytearray)\n",
        "    if isinstance(x, (bytes, bytearray)):\n",
        "        try:\n",
        "            return wkb.loads(x)\n",
        "        except Exception as e:\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Aplicar la función a la columna 'geom_wkb'\n",
        "df['geom'] = df['geom_wkb'].apply(safe_wkb_load)\n",
        "\n",
        "# Eliminar las columnas originales 'geometry' y 'geom_wkb'\n",
        "df = df.drop(columns=['geometry', 'geom_wkb'])\n",
        "\n",
        "# Crear el GeoDataFrame usando la columna 'geom' como geometría activa\n",
        "gdf = gpd.GeoDataFrame(df, geometry='geom', crs=\"EPSG:4326\")\n",
        "\n",
        "# Exportar a GeoPackage\n",
        "gdf.to_file(\"nacional_final_completa_censo.gpkg\", driver=\"GPKG\")\n",
        "\n",
        "print(\"GeoPackage 'nacional_final_completa_censo.gpkg' creado exitosamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZHBmGuELn--"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utb3dk3uvwBx"
      },
      "outputs": [],
      "source": [
        "gdf = gpd.read_file(\"nacional_final_completa_censo.gpkg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wbsb3B0UJKes"
      },
      "outputs": [],
      "source": [
        "gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-23D3GVRMU88"
      },
      "outputs": [],
      "source": [
        "gdf[\"epo_100\"] =  gdf[\"epo_100\"] - gdf[\"personal\"]\n",
        "gdf[\"epo_500\"] =  gdf[\"epo_500\"] - gdf[\"personal\"]\n",
        "gdf[\"act_46_100\"] =  gdf[\"act_46_100\"] - gdf[\"personal\"]\n",
        "gdf[\"act_46_500\"] =  gdf[\"act_46_500\"] - gdf[\"personal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgmIIek3MU_d"
      },
      "outputs": [],
      "source": [
        "X = gdf.drop(columns=['klass', 'id', 'codigo_act','codigo_act_2c','clee','nom_estab','cve_ent','personal','geometry']) #geom la primera vez jeje\n",
        "y = gdf[\"klass\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZcmw48uMVB0"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0uWswkhMVEM"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrOxnVz_xBZ_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg0b90t4MVJI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzvrqyikmcMr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyVbLP_Gx7G_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfOP-PVks2u9"
      },
      "outputs": [],
      "source": [
        "exported_pipeline = GradientBoostingClassifier(\n",
        "    learning_rate=0.05, max_depth=3, min_samples_leaf=14,\n",
        "    min_samples_split=7, n_estimators=100, subsample=0.8\n",
        ")\n",
        "\n",
        "exported_pipeline.fit(X_train, y_train)\n",
        "results = exported_pipeline.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCf7OFMlyGcj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Suponiendo que ya has entrenado el modelo:\n",
        "# exported_pipeline.fit(X_train, y_train)\n",
        "# results = exported_pipeline.predict(X_test)\n",
        "\n",
        "# Exactitud (accuracy)\n",
        "acc = accuracy_score(y_test, results)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "report = classification_report(y_test, results)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, results)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# (Opcional) Visualizar la matriz de confusión con seaborn\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "HZdvXmd-a7ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Guardar el modelo entrenado\n",
        "joblib.dump(exported_pipeline, 'trained_model.joblib')"
      ],
      "metadata": {
        "id": "-aUwjupbZqys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# denue_total_est_per_ocu_final_5.duckdb\n",
        "# datos_censo_nacional_s9.duckdb"
      ],
      "metadata": {
        "id": "8wquhfVtZrfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Crear directorio destino en Drive si no existe\n",
        "dest_dir = '/content/drive/MyDrive/COLMEX ML'\n",
        "\n",
        "# Lista de archivos a copiar\n",
        "archivos = [\n",
        "    '/content/denue_total_est_per_ocu_final_5.duckdb',\n",
        "    '/content/datos_censo_nacional_s9.duckdb'\n",
        "]\n",
        "\n",
        "# Copiar cada archivo\n",
        "for archivo in archivos:\n",
        "    try:\n",
        "        shutil.copy(archivo, dest_dir)\n",
        "        print(f\"✅ {os.path.basename(archivo)} copiado exitosamente a Drive\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ Error: {archivo} no encontrado en Colab\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error inesperado copiando {archivo}: {str(e)}\")\n",
        "\n",
        "# Verificar resultado final\n",
        "print(\"\\nArchivos en tu Drive después de la copia:\")\n",
        "print(os.listdir(dest_dir))"
      ],
      "metadata": {
        "id": "o5wlwGFXbj9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6qexnggcDb0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1r4VFM4q2LZeD2MTEBAyLroN-tw4Uw48T",
      "authorship_tag": "ABX9TyNMvvZ/b21Isd6UlcNAMkd1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}